{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports for data-preprocessing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from __future__ import print_function\n",
    "\n",
    "# Import for spliting the data set\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Imports for classificaiton \n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.decomposition import PCA \n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import metrics as mt\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Import for Statistical Comparison \n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classification to predict *Income* using the following methods: RandomForest, K-Nearest Neighbors, and Decision Trees\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import data\n",
    "df = pd.read_csv('../data/master.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>education</th>\n",
       "      <th>education_num</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital_gain</th>\n",
       "      <th>capital_loss</th>\n",
       "      <th>hours_per_week</th>\n",
       "      <th>native_country</th>\n",
       "      <th>income_binary</th>\n",
       "      <th>condensed_education</th>\n",
       "      <th>continent</th>\n",
       "      <th>condensed_marital</th>\n",
       "      <th>condensed_workclass</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>United States</td>\n",
       "      <td>Never</td>\n",
       "      <td>Government</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>United States</td>\n",
       "      <td>Married</td>\n",
       "      <td>Self-Employed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "      <td>High School Graduate</td>\n",
       "      <td>United States</td>\n",
       "      <td>Divorced/Separated</td>\n",
       "      <td>Private</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "      <td>No High School Diploma</td>\n",
       "      <td>United States</td>\n",
       "      <td>Married</td>\n",
       "      <td>Private</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>&lt;=50K</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>Caribbean</td>\n",
       "      <td>Married</td>\n",
       "      <td>Private</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  age         workclass   education  education_num  \\\n",
       "0           0   39         State-gov   Bachelors             13   \n",
       "1           1   50  Self-emp-not-inc   Bachelors             13   \n",
       "2           2   38           Private     HS-grad              9   \n",
       "3           3   53           Private        11th              7   \n",
       "4           4   28           Private   Bachelors             13   \n",
       "\n",
       "       marital_status          occupation    relationship    race      sex  \\\n",
       "0       Never-married        Adm-clerical   Not-in-family   White     Male   \n",
       "1  Married-civ-spouse     Exec-managerial         Husband   White     Male   \n",
       "2            Divorced   Handlers-cleaners   Not-in-family   White     Male   \n",
       "3  Married-civ-spouse   Handlers-cleaners         Husband   Black     Male   \n",
       "4  Married-civ-spouse      Prof-specialty            Wife   Black   Female   \n",
       "\n",
       "   capital_gain  capital_loss  hours_per_week native_country income_binary  \\\n",
       "0          2174             0              40  United-States         <=50K   \n",
       "1             0             0              13  United-States         <=50K   \n",
       "2             0             0              40  United-States         <=50K   \n",
       "3             0             0              40  United-States         <=50K   \n",
       "4             0             0              40           Cuba         <=50K   \n",
       "\n",
       "      condensed_education      continent   condensed_marital  \\\n",
       "0               Bachelors  United States               Never   \n",
       "1               Bachelors  United States             Married   \n",
       "2    High School Graduate  United States  Divorced/Separated   \n",
       "3  No High School Diploma  United States             Married   \n",
       "4               Bachelors      Caribbean             Married   \n",
       "\n",
       "  condensed_workclass  \n",
       "0          Government  \n",
       "1       Self-Employed  \n",
       "2             Private  \n",
       "3             Private  \n",
       "4             Private  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Delete unwanted variables\n",
    "del df['workclass']\n",
    "del df['education']\n",
    "del df['education_num']\n",
    "del df['marital_status']\n",
    "del df['occupation']\n",
    "del df['native_country'] \n",
    "del df['Unnamed: 0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital_gain</th>\n",
       "      <th>capital_loss</th>\n",
       "      <th>hours_per_week</th>\n",
       "      <th>income_binary</th>\n",
       "      <th>condensed_education</th>\n",
       "      <th>continent</th>\n",
       "      <th>condensed_marital</th>\n",
       "      <th>condensed_workclass</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>&lt;=50K</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>United States</td>\n",
       "      <td>Never</td>\n",
       "      <td>Government</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>&lt;=50K</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>United States</td>\n",
       "      <td>Married</td>\n",
       "      <td>Self-Employed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>&lt;=50K</td>\n",
       "      <td>High School Graduate</td>\n",
       "      <td>United States</td>\n",
       "      <td>Divorced/Separated</td>\n",
       "      <td>Private</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>&lt;=50K</td>\n",
       "      <td>No High School Diploma</td>\n",
       "      <td>United States</td>\n",
       "      <td>Married</td>\n",
       "      <td>Private</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>&lt;=50K</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>Caribbean</td>\n",
       "      <td>Married</td>\n",
       "      <td>Private</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age    relationship    race      sex  capital_gain  capital_loss  \\\n",
       "0   39   Not-in-family   White     Male          2174             0   \n",
       "1   50         Husband   White     Male             0             0   \n",
       "2   38   Not-in-family   White     Male             0             0   \n",
       "3   53         Husband   Black     Male             0             0   \n",
       "4   28            Wife   Black   Female             0             0   \n",
       "\n",
       "   hours_per_week income_binary     condensed_education      continent  \\\n",
       "0              40         <=50K               Bachelors  United States   \n",
       "1              13         <=50K               Bachelors  United States   \n",
       "2              40         <=50K    High School Graduate  United States   \n",
       "3              40         <=50K  No High School Diploma  United States   \n",
       "4              40         <=50K               Bachelors      Caribbean   \n",
       "\n",
       "    condensed_marital condensed_workclass  \n",
       "0               Never          Government  \n",
       "1             Married       Self-Employed  \n",
       "2  Divorced/Separated             Private  \n",
       "3             Married             Private  \n",
       "4             Married             Private  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check data \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 48842 entries, 0 to 48841\n",
      "Data columns (total 12 columns):\n",
      "age                    48842 non-null int64\n",
      "relationship           48842 non-null object\n",
      "race                   48842 non-null object\n",
      "sex                    48842 non-null object\n",
      "capital_gain           48842 non-null int64\n",
      "capital_loss           48842 non-null int64\n",
      "hours_per_week         48842 non-null int64\n",
      "income_binary          48842 non-null object\n",
      "condensed_education    48842 non-null object\n",
      "continent              48842 non-null object\n",
      "condensed_marital      48842 non-null object\n",
      "condensed_workclass    48842 non-null object\n",
      "dtypes: int64(4), object(8)\n",
      "memory usage: 4.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and Testing Split\n",
    "\n",
    "The goal of performing cross-validation is to split your data into a training set and test set. The training set is split up into multiple validation sets. We are going to use stratified K-fold cross-validation with 10 splits (K=10) for our classification tasks. This is because our data is unbalanced. There is a total of 48,842 individuals that were surveyed in our data set. Out of all the individuals surveyed, 41,762 are white, 32,650 are male, 37,155 have an income greater than or equal to 50K USD, 43,832 are from the United States, and 33,906 work in the private industry. Stratified K-fold cross-validation ensures that each of our training sets contains an equal proportion of each unbalanced variable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>income_binary</th>\n",
       "      <th>condensed_education</th>\n",
       "      <th>continent</th>\n",
       "      <th>condensed_marital</th>\n",
       "      <th>condensed_workclass</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>48842</td>\n",
       "      <td>48842</td>\n",
       "      <td>48842</td>\n",
       "      <td>48842</td>\n",
       "      <td>48842</td>\n",
       "      <td>48842</td>\n",
       "      <td>48842</td>\n",
       "      <td>48842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>&lt;=50K</td>\n",
       "      <td>High School Graduate</td>\n",
       "      <td>United States</td>\n",
       "      <td>Married</td>\n",
       "      <td>Private</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>19716</td>\n",
       "      <td>41762</td>\n",
       "      <td>32650</td>\n",
       "      <td>37155</td>\n",
       "      <td>15784</td>\n",
       "      <td>43832</td>\n",
       "      <td>23044</td>\n",
       "      <td>33906</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       relationship    race    sex income_binary   condensed_education  \\\n",
       "count         48842   48842  48842         48842                 48842   \n",
       "unique            6       5      2             2                     7   \n",
       "top         Husband   White   Male         <=50K  High School Graduate   \n",
       "freq          19716   41762  32650         37155                 15784   \n",
       "\n",
       "            continent condensed_marital condensed_workclass  \n",
       "count           48842             48842               48842  \n",
       "unique              9                 4                   4  \n",
       "top     United States           Married             Private  \n",
       "freq            43832             23044               33906  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe(exclude=[np.number])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TMccw\\Anaconda2\\lib\\site-packages\\sklearn\\utils\\validation.py:429: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, _DataConversionWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split the data into traning (80%) and test set (20%)\n",
    "# We are using stratified cross validation here because the majority of the\n",
    "#    individuals in the variable race are white\n",
    "\n",
    "if 'income_binary' in df:\n",
    "    y = df['income_binary'].values #get values we need \n",
    "    del df['income_binary']        #get rid of the class label\n",
    "    X = df.values                  #use everything else to predict \n",
    "    \n",
    "X = pd.get_dummies(df).values\n",
    "\n",
    "# Scale attributes by the training set\n",
    "scl = StandardScaler()\n",
    "X = scl.fit_transform(X)\n",
    "\n",
    "# Split the data into 20% Test and 80% Train using StratifiedShuffleSplit\n",
    "sss = StratifiedShuffleSplit(n_splits=10, test_size=0.20, random_state=111)\n",
    "sss.get_n_splits(X, y) #retreving the splits "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StratifiedShuffleSplit(n_splits=10, random_state=111, test_size=0.2,\n",
      "            train_size=None)\n"
     ]
    }
   ],
   "source": [
    "print(sss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: [15163 16279 29246 ..., 21159 41049 17832] TEST: [43578  1917 17027 ..., 22163 39121  5217]\n",
      "TRAIN: [12894 40784 33210 ..., 40386 25846 36294] TEST: [22078 13800    49 ..., 31283 31586  5940]\n",
      "TRAIN: [16738 39693 30388 ...,   328 33912 39362] TEST: [24310 48705 25069 ..., 47258 14625 39292]\n",
      "TRAIN: [ 7391 39777 43398 ...,  8978 24399 34458] TEST: [ 8836  1328 27156 ..., 47164 10476 15648]\n",
      "TRAIN: [16863 33361 41054 ..., 26744 47828 11941] TEST: [18495 35842 20752 ..., 46535  4696 46808]\n",
      "TRAIN: [ 5743 21257 30549 ...,  5927  7506 19162] TEST: [21737 30911  7484 ..., 19717 27662 19780]\n",
      "TRAIN: [18797 40559 21393 ..., 47376 19268 42562] TEST: [13861 34766  4320 ..., 42723 30153 11994]\n",
      "TRAIN: [36977 11147 24500 ..., 40130 15262 22626] TEST: [13974 35810 43678 ...,  7735 14376 40480]\n",
      "TRAIN: [32752 37107 19197 ..., 26015 32870  7076] TEST: [36370 13966 29812 ..., 20543 23045 34324]\n",
      "TRAIN: [22441 41471 48039 ..., 32784  4446 45905] TEST: [  934  1627 37667 ...,  4950 44845 21169]\n"
     ]
    }
   ],
   "source": [
    "# Create a for loop that grabs the values for each fold for traing and test sets\n",
    "for train_index, test_index in sss.split(X, y):\n",
    "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----Iteration 0  ----\n",
      "KNN accuracy = 0.83539768656\n",
      "KNN metric report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      <=50K       0.87      0.93      0.90      7431\n",
      "       >50K       0.70      0.54      0.61      2338\n",
      "\n",
      "avg / total       0.83      0.84      0.83      9769\n",
      "\n",
      "----Iteration 1  ----\n",
      "KNN accuracy = 0.839389906848\n",
      "KNN metric report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      <=50K       0.87      0.93      0.90      7431\n",
      "       >50K       0.71      0.56      0.63      2338\n",
      "\n",
      "avg / total       0.83      0.84      0.83      9769\n",
      "\n",
      "----Iteration 2  ----\n",
      "KNN accuracy = 0.833145664858\n",
      "KNN metric report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      <=50K       0.87      0.92      0.89      7431\n",
      "       >50K       0.69      0.56      0.61      2338\n",
      "\n",
      "avg / total       0.82      0.83      0.83      9769\n",
      "\n",
      "----Iteration 3  ----\n",
      "KNN accuracy = 0.830791278534\n",
      "KNN metric report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      <=50K       0.87      0.92      0.89      7431\n",
      "       >50K       0.68      0.55      0.61      2338\n",
      "\n",
      "avg / total       0.82      0.83      0.82      9769\n",
      "\n",
      "----Iteration 4  ----\n",
      "KNN accuracy = 0.833043300235\n",
      "KNN metric report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      <=50K       0.87      0.92      0.89      7431\n",
      "       >50K       0.68      0.56      0.62      2338\n",
      "\n",
      "avg / total       0.83      0.83      0.83      9769\n",
      "\n",
      "----Iteration 5  ----\n",
      "KNN accuracy = 0.835602415805\n",
      "KNN metric report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      <=50K       0.87      0.92      0.90      7431\n",
      "       >50K       0.69      0.56      0.62      2338\n",
      "\n",
      "avg / total       0.83      0.84      0.83      9769\n",
      "\n",
      "----Iteration 6  ----\n",
      "KNN accuracy = 0.837854437506\n",
      "KNN metric report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      <=50K       0.87      0.92      0.90      7431\n",
      "       >50K       0.70      0.57      0.63      2338\n",
      "\n",
      "avg / total       0.83      0.84      0.83      9769\n",
      "\n",
      "----Iteration 7  ----\n",
      "KNN accuracy = 0.833452758727\n",
      "KNN metric report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      <=50K       0.87      0.92      0.89      7431\n",
      "       >50K       0.69      0.56      0.62      2338\n",
      "\n",
      "avg / total       0.83      0.83      0.83      9769\n",
      "\n",
      "----Iteration 8  ----\n",
      "KNN accuracy = 0.837547343638\n",
      "KNN metric report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      <=50K       0.87      0.92      0.90      7431\n",
      "       >50K       0.70      0.57      0.63      2338\n",
      "\n",
      "avg / total       0.83      0.84      0.83      9769\n",
      "\n",
      "----Iteration 9  ----\n",
      "KNN accuracy = 0.838878083734\n",
      "KNN metric report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      <=50K       0.87      0.93      0.90      7431\n",
      "       >50K       0.71      0.55      0.62      2338\n",
      "\n",
      "avg / total       0.83      0.84      0.83      9769\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Classification with KNN on income_binary\n",
    "\n",
    "# Create reusable KNN object \n",
    "KNN = KNeighborsClassifier(n_neighbors=25)\n",
    "\n",
    "iter_num=0\n",
    "# the indices are the rows used for training and testing in each iteration\n",
    "for train_indices, test_indices in sss.split(X,y): \n",
    "    X_train = X[train_indices]  # train indices for X\n",
    "    y_train = y[train_indices]  # train indices for y\n",
    "    \n",
    "    X_test = X[test_indices]    # test indices for X\n",
    "    y_test = y[test_indices]    # test indices for y\n",
    "    \n",
    "    # train the reusable KNN classifier on the training data\n",
    "    KNN.fit(X_train,y_train)  # train object\n",
    "    y_hat = KNN.predict(X_test) # get test set precitions\n",
    "    \n",
    "    # Accuracy for the iterations of training/testing\n",
    "    accuracy_KNN = mt.accuracy_score(y_test,y_hat)  # obtain accuracies for each iteration \n",
    "    print(\"----Iteration\",iter_num,\" ----\")         # print out each numbered interation \n",
    "    print('KNN accuracy =', accuracy_KNN)            \n",
    "\n",
    "    #Metric report \n",
    "    metrics_KNN = classification_report(y_test,y_hat)  # obtain metric's report for each iteration \n",
    "    print('KNN metric report')\n",
    "    print(metrics_KNN)\n",
    "    iter_num+=1  # run through the first iteration, then second, then third ... then tenth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean accuracy for this model is  0.835510287645\n"
     ]
    }
   ],
   "source": [
    "# Get the mean accuracy\n",
    "\n",
    "# Load the accuracies\n",
    "accuracies_KNN = cross_val_score(KNN, X, y=y, cv=sss) # this also can help with parallelism\n",
    "\n",
    "# Print out the mean \n",
    "mean_KNN = np.mean(accuracies_KNN)\n",
    "print(\"The mean accuracy for this model is \", mean_KNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----Iteration 0  ----\n",
      "KNN PipeLine accuracy = 0.810727812468\n",
      "KNN & PCA metric report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      <=50K       0.85      0.92      0.88      7431\n",
      "       >50K       0.64      0.48      0.55      2338\n",
      "\n",
      "avg / total       0.80      0.81      0.80      9769\n",
      "\n",
      "----Iteration 1  ----\n",
      "KNN PipeLine accuracy = 0.814515303511\n",
      "KNN & PCA metric report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      <=50K       0.85      0.92      0.88      7431\n",
      "       >50K       0.65      0.48      0.55      2338\n",
      "\n",
      "avg / total       0.80      0.81      0.80      9769\n",
      "\n",
      "----Iteration 2  ----\n",
      "KNN PipeLine accuracy = 0.812468011055\n",
      "KNN & PCA metric report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      <=50K       0.85      0.91      0.88      7431\n",
      "       >50K       0.64      0.50      0.56      2338\n",
      "\n",
      "avg / total       0.80      0.81      0.80      9769\n",
      "\n",
      "----Iteration 3  ----\n",
      "KNN PipeLine accuracy = 0.811034906336\n",
      "KNN & PCA metric report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      <=50K       0.85      0.91      0.88      7431\n",
      "       >50K       0.64      0.48      0.55      2338\n",
      "\n",
      "avg / total       0.80      0.81      0.80      9769\n",
      "\n",
      "----Iteration 4  ----\n",
      "KNN PipeLine accuracy = 0.815743678985\n",
      "KNN & PCA metric report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      <=50K       0.85      0.92      0.88      7431\n",
      "       >50K       0.65      0.49      0.56      2338\n",
      "\n",
      "avg / total       0.80      0.82      0.81      9769\n",
      "\n",
      "----Iteration 5  ----\n",
      "KNN PipeLine accuracy = 0.817995700686\n",
      "KNN & PCA metric report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      <=50K       0.85      0.92      0.89      7431\n",
      "       >50K       0.66      0.49      0.56      2338\n",
      "\n",
      "avg / total       0.81      0.82      0.81      9769\n",
      "\n",
      "----Iteration 6  ----\n",
      "KNN PipeLine accuracy = 0.816767325212\n",
      "KNN & PCA metric report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      <=50K       0.86      0.91      0.88      7431\n",
      "       >50K       0.65      0.51      0.57      2338\n",
      "\n",
      "avg / total       0.81      0.82      0.81      9769\n",
      "\n",
      "----Iteration 7  ----\n",
      "KNN PipeLine accuracy = 0.807554509162\n",
      "KNN & PCA metric report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      <=50K       0.85      0.91      0.88      7431\n",
      "       >50K       0.63      0.48      0.54      2338\n",
      "\n",
      "avg / total       0.80      0.81      0.80      9769\n",
      "\n",
      "----Iteration 8  ----\n",
      "KNN PipeLine accuracy = 0.813696386529\n",
      "KNN & PCA metric report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      <=50K       0.85      0.92      0.88      7431\n",
      "       >50K       0.65      0.47      0.55      2338\n",
      "\n",
      "avg / total       0.80      0.81      0.80      9769\n",
      "\n",
      "----Iteration 9  ----\n",
      "KNN PipeLine accuracy = 0.81338929266\n",
      "KNN & PCA metric report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      <=50K       0.85      0.92      0.88      7431\n",
      "       >50K       0.65      0.47      0.55      2338\n",
      "\n",
      "avg / total       0.80      0.81      0.80      9769\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Lets train a PipeLine with PCA to see if we can increase the accuracy \n",
    "\n",
    "# First we need to set up the PipeLine that will take the PCA and then fit a KNN classifier\n",
    "KNN_pipe = Pipeline([('PCA',PCA(n_components=2,svd_solver='randomized')),\n",
    "     ('KNN',KNeighborsClassifier(n_neighbors=25))])\n",
    "\n",
    "# Next we need to iterate through and get the prediction, like we did above\n",
    "iter_num=0\n",
    "# the indices are the rows used for training and testing in each iteration\n",
    "for train_indices, test_indices in sss.split(X,y): \n",
    "    X_train = X[train_indices]  # train indices for X\n",
    "    y_train = y[train_indices]  # train indices for y\n",
    "    \n",
    "    X_test = X[test_indices]    # test indices for X\n",
    "    y_test = y[test_indices]    # test indices for y\n",
    "    \n",
    "    # train the reusable KNN classifier on the training data\n",
    "    KNN_pipe.fit(X_train,y_train)    # train object\n",
    "    y_hat = KNN_pipe.predict(X_test) # get test set precitions\n",
    "    \n",
    "    # accuracy for the iterations of training/testing\n",
    "    accuracy_KNN_pipe = mt.accuracy_score(y_test,y_hat)  # obtain accuracies for each iteration \n",
    "    print(\"----Iteration\",iter_num,\" ----\")              # print out each numbered interation \n",
    "    print('KNN PipeLine accuracy =', accuracy_KNN_pipe)\n",
    "    \n",
    "    #Metric report \n",
    "    metrics_KNN_pipe = classification_report(y_test,y_hat)  # obtain metric's report for each iteration \n",
    "    print('KNN & PCA metric report')\n",
    "    print(metrics_KNN_pipe)\n",
    "    iter_num+=1  # run through the first iteration, then second, then third ... then tenth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we are going to use a different classifier, Random Forest, to see if we can improve our accuracy and also control over-fitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean accuracy for this model is  0.812519193367\n"
     ]
    }
   ],
   "source": [
    "# Get the mean accuracy\n",
    "\n",
    "# Load the accuracies\n",
    "accuracies_KNN_pipe = cross_val_score(KNN_pipe, X, y=y, cv=sss) # this also can help with parallelism\n",
    "\n",
    "# Print out the mean \n",
    "mean_KNN_pipe = np.mean(accuracies_KNN_pipe)\n",
    "print(\"The mean accuracy for this model is \", mean_KNN_pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. The mean accuracy for KNN model is  0.835510287645\n",
      "------------------------------------------------------------------------\n",
      "2. The mean accuracy for KNN with PCA model is  0.812519193367\n",
      "------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Accuracies for comparision for each KNN model \n",
    "\n",
    "# KNN model 1\n",
    "print(\"1. The mean accuracy for KNN model is \", mean_KNN)\n",
    "print('------------------------------------------------------------------------')\n",
    "\n",
    "# RF model 2\n",
    "print(\"2. The mean accuracy for KNN with PCA model is \", mean_KNN_pipe)\n",
    "print('------------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The mean accuracy for the K-Nearest Neighbor model without the PCA is 83.55%. This is the model we are going to choose for this classifier. Next, we will run a Random Forest classifier and then compare the two classifiers together to see which one generates the highest accuracy for our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----Iteration 0  ----\n",
      "RF accuracy = 0.838570989866\n",
      "RF metric report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      <=50K       0.88      0.91      0.90      7431\n",
      "       >50K       0.69      0.60      0.64      2338\n",
      "\n",
      "avg / total       0.83      0.84      0.83      9769\n",
      "\n",
      "----Iteration 1  ----\n",
      "RF accuracy = 0.839901729962\n",
      "RF metric report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      <=50K       0.88      0.92      0.90      7431\n",
      "       >50K       0.69      0.60      0.64      2338\n",
      "\n",
      "avg / total       0.83      0.84      0.84      9769\n",
      "\n",
      "----Iteration 2  ----\n",
      "RF accuracy = 0.83724024977\n",
      "RF metric report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      <=50K       0.88      0.91      0.90      7431\n",
      "       >50K       0.68      0.60      0.64      2338\n",
      "\n",
      "avg / total       0.83      0.84      0.83      9769\n",
      "\n",
      "----Iteration 3  ----\n",
      "RF accuracy = 0.840720646944\n",
      "RF metric report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      <=50K       0.88      0.92      0.90      7431\n",
      "       >50K       0.69      0.60      0.64      2338\n",
      "\n",
      "avg / total       0.83      0.84      0.84      9769\n",
      "\n",
      "----Iteration 4  ----\n",
      "RF accuracy = 0.840413553076\n",
      "RF metric report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      <=50K       0.88      0.92      0.90      7431\n",
      "       >50K       0.69      0.60      0.64      2338\n",
      "\n",
      "avg / total       0.83      0.84      0.84      9769\n",
      "\n",
      "----Iteration 5  ----\n",
      "RF accuracy = 0.836011874296\n",
      "RF metric report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      <=50K       0.88      0.92      0.89      7431\n",
      "       >50K       0.68      0.58      0.63      2338\n",
      "\n",
      "avg / total       0.83      0.84      0.83      9769\n",
      "\n",
      "----Iteration 6  ----\n",
      "RF accuracy = 0.841744293172\n",
      "RF metric report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      <=50K       0.88      0.92      0.90      7431\n",
      "       >50K       0.70      0.60      0.65      2338\n",
      "\n",
      "avg / total       0.84      0.84      0.84      9769\n",
      "\n",
      "----Iteration 7  ----\n",
      "RF accuracy = 0.839389906848\n",
      "RF metric report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      <=50K       0.88      0.92      0.90      7431\n",
      "       >50K       0.69      0.60      0.64      2338\n",
      "\n",
      "avg / total       0.83      0.84      0.84      9769\n",
      "\n",
      "----Iteration 8  ----\n",
      "RF accuracy = 0.840515917699\n",
      "RF metric report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      <=50K       0.88      0.92      0.90      7431\n",
      "       >50K       0.70      0.59      0.64      2338\n",
      "\n",
      "avg / total       0.83      0.84      0.84      9769\n",
      "\n",
      "----Iteration 9  ----\n",
      "RF accuracy = 0.843075033269\n",
      "RF metric report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      <=50K       0.88      0.92      0.90      7431\n",
      "       >50K       0.70      0.60      0.65      2338\n",
      "\n",
      "avg / total       0.84      0.84      0.84      9769\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Classification with RandomForest\n",
    "\n",
    "# No parameter adjustments\n",
    "\n",
    "RF = RandomForestClassifier(random_state=111)\n",
    "\n",
    "# Now we want to iterate through and grab the prediction, just like we did in the KNN above\n",
    "iter_num=0\n",
    "# the indices are the rows used for training and testing in each iteration\n",
    "for train_indices, test_indices in sss.split(X,y): \n",
    "    X_train = X[train_indices]  # train indices for X\n",
    "    y_train = y[train_indices]  # train indices for y\n",
    "    \n",
    "    X_test = X[test_indices]    # test indices for X\n",
    "    y_test = y[test_indices]    # test indices for y\n",
    "    \n",
    "    # train the reusable KNN classifier on the training data\n",
    "    RF.fit(X_train,y_train)  # train object\n",
    "    y_hat = RF.predict(X_test) # get test set precitions\n",
    "    \n",
    "    # Accuracy for the iterations of training/testing\n",
    "    accuracy_RF = mt.accuracy_score(y_test,y_hat)    # obtain accuracies for each iteration \n",
    "    print(\"----Iteration\",iter_num,\" ----\")          # print out each numbered interation \n",
    "    print('RF accuracy =', accuracy_RF)\n",
    "\n",
    "    # Metric report \n",
    "    metrics_RF = classification_report(y_test,y_hat)\n",
    "    print('RF metric report')\n",
    "    print(metrics_RF)\n",
    "    iter_num+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean accuracy for this model is  0.83975841949\n"
     ]
    }
   ],
   "source": [
    "# Get the mean accuracy\n",
    "\n",
    "# Load the accuracies\n",
    "accuracies_RF = cross_val_score(RF, X, y=y, cv=sss) # this also can help with parallelism\n",
    "\n",
    "# Print out the mean \n",
    "mean_RF = np.mean(accuracies_RF)\n",
    "print(\"The mean accuracy for this model is \", mean_RF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model below will incorporate a few parameter adjustments. First, we will add a max depth which is the max depth of the tree. When this is not added to the model parameters, the nodes are expanded until all leaves are pure. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----Iteration 0  ----\n",
      "RF2 accuracy = 0.853311495547\n",
      "RF2 metric report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      <=50K       0.87      0.95      0.91      7431\n",
      "       >50K       0.77      0.55      0.64      2338\n",
      "\n",
      "avg / total       0.85      0.85      0.84      9769\n",
      "\n",
      "----Iteration 1  ----\n",
      "RF2 accuracy = 0.858532091309\n",
      "RF2 metric report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      <=50K       0.87      0.95      0.91      7431\n",
      "       >50K       0.79      0.55      0.65      2338\n",
      "\n",
      "avg / total       0.85      0.86      0.85      9769\n",
      "\n",
      "----Iteration 2  ----\n",
      "RF2 accuracy = 0.854642235643\n",
      "RF2 metric report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      <=50K       0.87      0.96      0.91      7431\n",
      "       >50K       0.80      0.53      0.63      2338\n",
      "\n",
      "avg / total       0.85      0.85      0.84      9769\n",
      "\n",
      "----Iteration 3  ----\n",
      "RF2 accuracy = 0.851161838469\n",
      "RF2 metric report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      <=50K       0.87      0.95      0.91      7431\n",
      "       >50K       0.77      0.54      0.64      2338\n",
      "\n",
      "avg / total       0.84      0.85      0.84      9769\n",
      "\n",
      "----Iteration 4  ----\n",
      "RF2 accuracy = 0.854949329512\n",
      "RF2 metric report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      <=50K       0.86      0.97      0.91      7431\n",
      "       >50K       0.82      0.51      0.63      2338\n",
      "\n",
      "avg / total       0.85      0.85      0.84      9769\n",
      "\n",
      "----Iteration 5  ----\n",
      "RF2 accuracy = 0.856689528099\n",
      "RF2 metric report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      <=50K       0.86      0.97      0.91      7431\n",
      "       >50K       0.83      0.51      0.63      2338\n",
      "\n",
      "avg / total       0.85      0.86      0.84      9769\n",
      "\n",
      "----Iteration 6  ----\n",
      "RF2 accuracy = 0.855665881871\n",
      "RF2 metric report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      <=50K       0.87      0.96      0.91      7431\n",
      "       >50K       0.80      0.53      0.64      2338\n",
      "\n",
      "avg / total       0.85      0.86      0.84      9769\n",
      "\n",
      "----Iteration 7  ----\n",
      "RF2 accuracy = 0.851673661583\n",
      "RF2 metric report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      <=50K       0.86      0.96      0.91      7431\n",
      "       >50K       0.81      0.50      0.62      2338\n",
      "\n",
      "avg / total       0.85      0.85      0.84      9769\n",
      "\n",
      "----Iteration 8  ----\n",
      "RF2 accuracy = 0.858429726686\n",
      "RF2 metric report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      <=50K       0.87      0.96      0.91      7431\n",
      "       >50K       0.80      0.54      0.65      2338\n",
      "\n",
      "avg / total       0.85      0.86      0.85      9769\n",
      "\n",
      "----Iteration 9  ----\n",
      "RF2 accuracy = 0.856075340362\n",
      "RF2 metric report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      <=50K       0.86      0.96      0.91      7431\n",
      "       >50K       0.81      0.52      0.63      2338\n",
      "\n",
      "avg / total       0.85      0.86      0.84      9769\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create an object that holds the second RF model with parameter adjustments\n",
    "\n",
    "RF2= RandomForestClassifier(max_depth=10, random_state=111)\n",
    "\n",
    "# Now we want to iterate through and grab the prediction, just like we did in the RF above\n",
    "# Now we want to iterate through and grab the prediction, just like we did in the KNN above\n",
    "iter_num=0\n",
    "# the indices are the rows used for training and testing in each iteration\n",
    "for train_indices, test_indices in sss.split(X,y): \n",
    "    X_train = X[train_indices]  # train indices for X\n",
    "    y_train = y[train_indices]  # train indices for y\n",
    "    \n",
    "    X_test = X[test_indices]    # test indices for X\n",
    "    y_test = y[test_indices]    # test indices for y\n",
    "    \n",
    "    # train the reusable KNN classifier on the training data\n",
    "    RF2.fit(X_train,y_train)  # train object\n",
    "    y_hat = RF2.predict(X_test) # get test set precitions\n",
    "    \n",
    "    # Accuracy for the iterations of training/testing\n",
    "    accuracy_RF2 = mt.accuracy_score(y_test,y_hat)   # obtain accuracies for each iteration \n",
    "    print(\"----Iteration\",iter_num,\" ----\")          # print out each numbered interation \n",
    "    print('RF2 accuracy =', accuracy_RF2)\n",
    "\n",
    "    # Metric report \n",
    "    metrics_RF2 = classification_report(y_test,y_hat)\n",
    "    print('RF2 metric report')\n",
    "    print(metrics_RF2)\n",
    "    iter_num+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean accuracy for this model is  0.855113112908\n"
     ]
    }
   ],
   "source": [
    "# Get the mean accuracy\n",
    "\n",
    "# Load the accuracies\n",
    "accuracies_RF2 = cross_val_score(RF2, X, y=y, cv=sss) # this also can help with parallelism\n",
    "\n",
    "# Print out the mean \n",
    "mean_RF2 = np.mean(accuracies_RF2)\n",
    "print(\"The mean accuracy for this model is \", mean_RF2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----Iteration 0  ----\n",
      "RF3 accuracy = 0.855665881871\n",
      "RF3 metric report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      <=50K       0.87      0.95      0.91      7431\n",
      "       >50K       0.77      0.57      0.65      2338\n",
      "\n",
      "avg / total       0.85      0.86      0.85      9769\n",
      "\n",
      "----Iteration 1  ----\n",
      "RF3 accuracy = 0.860681748388\n",
      "RF3 metric report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      <=50K       0.88      0.94      0.91      7431\n",
      "       >50K       0.77      0.60      0.67      2338\n",
      "\n",
      "avg / total       0.85      0.86      0.85      9769\n",
      "\n",
      "----Iteration 2  ----\n",
      "RF3 accuracy = 0.850035827618\n",
      "RF3 metric report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      <=50K       0.88      0.93      0.90      7431\n",
      "       >50K       0.73      0.59      0.65      2338\n",
      "\n",
      "avg / total       0.84      0.85      0.84      9769\n",
      "\n",
      "----Iteration 3  ----\n",
      "RF3 accuracy = 0.850035827618\n",
      "RF3 metric report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      <=50K       0.88      0.94      0.90      7431\n",
      "       >50K       0.74      0.58      0.65      2338\n",
      "\n",
      "avg / total       0.84      0.85      0.84      9769\n",
      "\n",
      "----Iteration 4  ----\n",
      "RF3 accuracy = 0.850240556864\n",
      "RF3 metric report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      <=50K       0.88      0.93      0.90      7431\n",
      "       >50K       0.74      0.58      0.65      2338\n",
      "\n",
      "avg / total       0.84      0.85      0.84      9769\n",
      "\n",
      "----Iteration 5  ----\n",
      "RF3 accuracy = 0.856075340362\n",
      "RF3 metric report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      <=50K       0.88      0.94      0.91      7431\n",
      "       >50K       0.76      0.58      0.66      2338\n",
      "\n",
      "avg / total       0.85      0.86      0.85      9769\n",
      "\n",
      "----Iteration 6  ----\n",
      "RF3 accuracy = 0.854846964889\n",
      "RF3 metric report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      <=50K       0.88      0.94      0.91      7431\n",
      "       >50K       0.75      0.59      0.66      2338\n",
      "\n",
      "avg / total       0.85      0.85      0.85      9769\n",
      "\n",
      "----Iteration 7  ----\n",
      "RF3 accuracy = 0.850752379977\n",
      "RF3 metric report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      <=50K       0.88      0.94      0.91      7431\n",
      "       >50K       0.74      0.58      0.65      2338\n",
      "\n",
      "avg / total       0.84      0.85      0.84      9769\n",
      "\n",
      "----Iteration 8  ----\n",
      "RF3 accuracy = 0.854949329512\n",
      "RF3 metric report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      <=50K       0.88      0.94      0.91      7431\n",
      "       >50K       0.75      0.59      0.66      2338\n",
      "\n",
      "avg / total       0.85      0.85      0.85      9769\n",
      "\n",
      "----Iteration 9  ----\n",
      "RF3 accuracy = 0.859453372914\n",
      "RF3 metric report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      <=50K       0.88      0.94      0.91      7431\n",
      "       >50K       0.77      0.60      0.67      2338\n",
      "\n",
      "avg / total       0.85      0.86      0.85      9769\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create an object that holds the third RF model with parameter adjustments\n",
    "\n",
    "RF3 = RandomForestClassifier(max_depth=20, random_state=111)\n",
    "\n",
    "# Now we want to iterate through and grab the prediction, just like we did in the RF2 above\n",
    "iter_num=0\n",
    "# The indices are the rows used for training and testing in each iteration\n",
    "for train_indices, test_indices in sss.split(X,y): \n",
    "    X_train = X[train_indices]  #train indices for X\n",
    "    y_train = y[train_indices]  #train indices for y\n",
    "    \n",
    "    X_test = X[test_indices]    #test indices for X\n",
    "    y_test = y[test_indices]    #test indices for y\n",
    "    \n",
    "    # Train the reusable KNN classifier on the training data\n",
    "    RF3.fit(X_train,y_train)  # train object\n",
    "    y_hat = RF3.predict(X_test) #get the test set predictions \n",
    "    \n",
    "    # Accuracy for the iterations of training/testing\n",
    "    accuracy_RF3= mt.accuracy_score(y_test,y_hat)    # obtain accuracies for each iteration \n",
    "    print(\"----Iteration\",iter_num,\" ----\")          # print out each numbered interation \n",
    "    print('RF3 accuracy =', accuracy_RF3)\n",
    "\n",
    "    # Metric report \n",
    "    metrics_RF3 = classification_report(y_test,y_hat)\n",
    "    print('RF3 metric report')\n",
    "    print(metrics_RF3)\n",
    "    iter_num+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean accuracy for this model is  0.854273723001\n"
     ]
    }
   ],
   "source": [
    "# Get the mean accuracy\n",
    "\n",
    "# Load the accuracies\n",
    "accuracies_RF3 = cross_val_score(RF3, X, y=y, cv=sss) # this also can help with parallelism\n",
    "\n",
    "# Print out the mean \n",
    "mean_RF3 = np.mean(accuracies_RF3)\n",
    "print(\"The mean accuracy for this model is \", mean_RF3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----Iteration 0  ----\n",
      "RF4 accuracy = 0.838570989866\n",
      "RF4 metric report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      <=50K       0.88      0.91      0.90      7431\n",
      "       >50K       0.69      0.60      0.64      2338\n",
      "\n",
      "avg / total       0.83      0.84      0.83      9769\n",
      "\n",
      "----Iteration 1  ----\n",
      "RF4 accuracy = 0.839901729962\n",
      "RF4 metric report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      <=50K       0.88      0.92      0.90      7431\n",
      "       >50K       0.69      0.60      0.64      2338\n",
      "\n",
      "avg / total       0.83      0.84      0.84      9769\n",
      "\n",
      "----Iteration 2  ----\n",
      "RF4 accuracy = 0.83724024977\n",
      "RF4 metric report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      <=50K       0.88      0.91      0.90      7431\n",
      "       >50K       0.68      0.60      0.64      2338\n",
      "\n",
      "avg / total       0.83      0.84      0.83      9769\n",
      "\n",
      "----Iteration 3  ----\n",
      "RF4 accuracy = 0.840720646944\n",
      "RF4 metric report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      <=50K       0.88      0.92      0.90      7431\n",
      "       >50K       0.69      0.60      0.64      2338\n",
      "\n",
      "avg / total       0.83      0.84      0.84      9769\n",
      "\n",
      "----Iteration 4  ----\n",
      "RF4 accuracy = 0.840413553076\n",
      "RF4 metric report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      <=50K       0.88      0.92      0.90      7431\n",
      "       >50K       0.69      0.60      0.64      2338\n",
      "\n",
      "avg / total       0.83      0.84      0.84      9769\n",
      "\n",
      "----Iteration 5  ----\n",
      "RF4 accuracy = 0.836011874296\n",
      "RF4 metric report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      <=50K       0.88      0.92      0.89      7431\n",
      "       >50K       0.68      0.58      0.63      2338\n",
      "\n",
      "avg / total       0.83      0.84      0.83      9769\n",
      "\n",
      "----Iteration 6  ----\n",
      "RF4 accuracy = 0.841744293172\n",
      "RF4 metric report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      <=50K       0.88      0.92      0.90      7431\n",
      "       >50K       0.70      0.60      0.65      2338\n",
      "\n",
      "avg / total       0.84      0.84      0.84      9769\n",
      "\n",
      "----Iteration 7  ----\n",
      "RF4 accuracy = 0.839389906848\n",
      "RF4 metric report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      <=50K       0.88      0.92      0.90      7431\n",
      "       >50K       0.69      0.60      0.64      2338\n",
      "\n",
      "avg / total       0.83      0.84      0.84      9769\n",
      "\n",
      "----Iteration 8  ----\n",
      "RF4 accuracy = 0.840515917699\n",
      "RF4 metric report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      <=50K       0.88      0.92      0.90      7431\n",
      "       >50K       0.70      0.59      0.64      2338\n",
      "\n",
      "avg / total       0.83      0.84      0.84      9769\n",
      "\n",
      "----Iteration 9  ----\n",
      "RF4 accuracy = 0.843075033269\n",
      "RF4 metric report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      <=50K       0.88      0.92      0.90      7431\n",
      "       >50K       0.70      0.60      0.65      2338\n",
      "\n",
      "avg / total       0.84      0.84      0.84      9769\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create an object that holds the third RF model with parameter adjustments\n",
    "\n",
    "RF4 = RandomForestClassifier(max_depth=100, random_state=111)\n",
    "\n",
    "# Now we want to iterate through and grab the prediction, just like we did in the RF3 above\n",
    "iter_num=0\n",
    "# The indices are the rows used for training and testing in each iteration\n",
    "for train_indices, test_indices in sss.split(X,y): \n",
    "    X_train = X[train_indices]  #train indices for X\n",
    "    y_train = y[train_indices]  #train indices for y\n",
    "    \n",
    "    X_test = X[test_indices]    #test indices for X\n",
    "    y_test = y[test_indices]    #test indices for y\n",
    "    \n",
    "    # Train the reusable KNN classifier on the training data\n",
    "    RF4.fit(X_train,y_train)  # train object\n",
    "    y_hat = RF4.predict(X_test) #get the test set predictions \n",
    "    \n",
    "    # Accuracy for the iterations of training/testing\n",
    "    accuracy_RF4= mt.accuracy_score(y_test,y_hat)    # obtain accuracies for each iteration \n",
    "    print(\"----Iteration\",iter_num,\" ----\")          # print out each numbered interation \n",
    "    print('RF4 accuracy =', accuracy_RF4)\n",
    "\n",
    "    # Metric report \n",
    "    metrics_RF4 = classification_report(y_test,y_hat)\n",
    "    print('RF4 metric report')\n",
    "    print(metrics_RF4)\n",
    "    iter_num+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean accuracy for this model is  0.83975841949\n"
     ]
    }
   ],
   "source": [
    "# Get the mean accuracy\n",
    "\n",
    "# Load the accuracies\n",
    "accuracies_RF4 = cross_val_score(RF4, X, y=y, cv=sss) # this also can help with parallelism\n",
    "\n",
    "# Print out the mean \n",
    "mean_RF4 = np.mean(accuracies_RF4)\n",
    "print(\"The mean accuracy for this model is \", mean_RF4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----Iteration 0  ----\n",
      "RF5 accuracy = 0.838468625243\n",
      "RF5 metric report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      <=50K       0.88      0.91      0.90      7431\n",
      "       >50K       0.69      0.60      0.64      2338\n",
      "\n",
      "avg / total       0.83      0.84      0.83      9769\n",
      "\n",
      "----Iteration 1  ----\n",
      "RF5 accuracy = 0.840004094585\n",
      "RF5 metric report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      <=50K       0.88      0.92      0.90      7431\n",
      "       >50K       0.69      0.60      0.64      2338\n",
      "\n",
      "avg / total       0.83      0.84      0.84      9769\n",
      "\n",
      "----Iteration 2  ----\n",
      "RF5 accuracy = 0.836626062033\n",
      "RF5 metric report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      <=50K       0.88      0.91      0.89      7431\n",
      "       >50K       0.68      0.59      0.64      2338\n",
      "\n",
      "avg / total       0.83      0.84      0.83      9769\n",
      "\n",
      "----Iteration 3  ----\n",
      "RF5 accuracy = 0.840823011567\n",
      "RF5 metric report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      <=50K       0.88      0.92      0.90      7431\n",
      "       >50K       0.69      0.60      0.64      2338\n",
      "\n",
      "avg / total       0.83      0.84      0.84      9769\n",
      "\n",
      "----Iteration 4  ----\n",
      "RF5 accuracy = 0.84020882383\n",
      "RF5 metric report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      <=50K       0.88      0.92      0.90      7431\n",
      "       >50K       0.69      0.60      0.64      2338\n",
      "\n",
      "avg / total       0.83      0.84      0.84      9769\n",
      "\n",
      "----Iteration 5  ----\n",
      "RF5 accuracy = 0.836011874296\n",
      "RF5 metric report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      <=50K       0.88      0.92      0.89      7431\n",
      "       >50K       0.68      0.58      0.63      2338\n",
      "\n",
      "avg / total       0.83      0.84      0.83      9769\n",
      "\n",
      "----Iteration 6  ----\n",
      "RF5 accuracy = 0.841232470058\n",
      "RF5 metric report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      <=50K       0.88      0.92      0.90      7431\n",
      "       >50K       0.69      0.60      0.64      2338\n",
      "\n",
      "avg / total       0.84      0.84      0.84      9769\n",
      "\n",
      "----Iteration 7  ----\n",
      "RF5 accuracy = 0.839389906848\n",
      "RF5 metric report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      <=50K       0.88      0.92      0.90      7431\n",
      "       >50K       0.69      0.60      0.64      2338\n",
      "\n",
      "avg / total       0.83      0.84      0.84      9769\n",
      "\n",
      "----Iteration 8  ----\n",
      "RF5 accuracy = 0.839901729962\n",
      "RF5 metric report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      <=50K       0.88      0.92      0.90      7431\n",
      "       >50K       0.70      0.59      0.64      2338\n",
      "\n",
      "avg / total       0.83      0.84      0.84      9769\n",
      "\n",
      "----Iteration 9  ----\n",
      "RF5 accuracy = 0.84348449176\n",
      "RF5 metric report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      <=50K       0.88      0.92      0.90      7431\n",
      "       >50K       0.70      0.60      0.65      2338\n",
      "\n",
      "avg / total       0.84      0.84      0.84      9769\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create an object that holds the third RF model with parameter adjustments\n",
    "\n",
    "RF5 = RandomForestClassifier(max_depth=50, random_state=111)\n",
    "\n",
    "# Now we want to iterate through and grab the prediction, just like we did in the RF4 above\n",
    "iter_num=0\n",
    "# The indices are the rows used for training and testing in each iteration\n",
    "for train_indices, test_indices in sss.split(X,y): \n",
    "    X_train = X[train_indices]  #train indices for X\n",
    "    y_train = y[train_indices]  #train indices for y\n",
    "    \n",
    "    X_test = X[test_indices]    #test indices for X\n",
    "    y_test = y[test_indices]    #test indices for y\n",
    "    \n",
    "    # Train the reusable KNN classifier on the training data\n",
    "    RF5.fit(X_train,y_train)  # train object\n",
    "    y_hat = RF5.predict(X_test) #get the test set predictions \n",
    "    \n",
    "    # Accuracy for the iterations of training/testing\n",
    "    accuracy_RF5= mt.accuracy_score(y_test,y_hat)    # obtain accuracies for each iteration \n",
    "    print(\"----Iteration\",iter_num,\" ----\")          # print out each numbered interation \n",
    "    print('RF5 accuracy =', accuracy_RF5)\n",
    "\n",
    "    # Metric report \n",
    "    metrics_RF5 = classification_report(y_test,y_hat)\n",
    "    print('RF5 metric report')\n",
    "    print(metrics_RF5)\n",
    "    iter_num+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean accuracy for this model is  0.839615109018\n"
     ]
    }
   ],
   "source": [
    "# Get the mean accuracy\n",
    "\n",
    "# Load the accuracies\n",
    "accuracies_RF5 = cross_val_score(RF5, X, y=y, cv=sss) # this also can help with parallelism\n",
    "\n",
    "# Print out the mean \n",
    "mean_RF5 = np.mean(accuracies_RF5)\n",
    "print(\"The mean accuracy for this model is \", mean_RF5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----Iteration 0  ----\n",
      "RF6 accuracy = 0.849933462995\n",
      "RF6 metric report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      <=50K       0.88      0.93      0.90      7431\n",
      "       >50K       0.73      0.59      0.65      2338\n",
      "\n",
      "avg / total       0.84      0.85      0.84      9769\n",
      "\n",
      "----Iteration 1  ----\n",
      "RF6 accuracy = 0.853004401679\n",
      "RF6 metric report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      <=50K       0.88      0.93      0.91      7431\n",
      "       >50K       0.73      0.61      0.67      2338\n",
      "\n",
      "avg / total       0.85      0.85      0.85      9769\n",
      "\n",
      "----Iteration 2  ----\n",
      "RF6 accuracy = 0.845838878084\n",
      "RF6 metric report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      <=50K       0.88      0.93      0.90      7431\n",
      "       >50K       0.71      0.59      0.65      2338\n",
      "\n",
      "avg / total       0.84      0.85      0.84      9769\n",
      "\n",
      "----Iteration 3  ----\n",
      "RF6 accuracy = 0.843893950251\n",
      "RF6 metric report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      <=50K       0.88      0.92      0.90      7431\n",
      "       >50K       0.71      0.59      0.65      2338\n",
      "\n",
      "avg / total       0.84      0.84      0.84      9769\n",
      "\n",
      "----Iteration 4  ----\n",
      "RF6 accuracy = 0.84716961818\n",
      "RF6 metric report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      <=50K       0.88      0.93      0.90      7431\n",
      "       >50K       0.72      0.59      0.65      2338\n",
      "\n",
      "avg / total       0.84      0.85      0.84      9769\n",
      "\n",
      "----Iteration 5  ----\n",
      "RF6 accuracy = 0.850342921486\n",
      "RF6 metric report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      <=50K       0.88      0.93      0.90      7431\n",
      "       >50K       0.73      0.59      0.65      2338\n",
      "\n",
      "avg / total       0.84      0.85      0.84      9769\n",
      "\n",
      "----Iteration 6  ----\n",
      "RF6 accuracy = 0.850957109223\n",
      "RF6 metric report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      <=50K       0.88      0.93      0.90      7431\n",
      "       >50K       0.73      0.61      0.66      2338\n",
      "\n",
      "avg / total       0.84      0.85      0.85      9769\n",
      "\n",
      "----Iteration 7  ----\n",
      "RF6 accuracy = 0.850547650732\n",
      "RF6 metric report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      <=50K       0.88      0.93      0.90      7431\n",
      "       >50K       0.73      0.60      0.66      2338\n",
      "\n",
      "avg / total       0.84      0.85      0.85      9769\n",
      "\n",
      "----Iteration 8  ----\n",
      "RF6 accuracy = 0.848602722899\n",
      "RF6 metric report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      <=50K       0.88      0.93      0.90      7431\n",
      "       >50K       0.72      0.59      0.65      2338\n",
      "\n",
      "avg / total       0.84      0.85      0.84      9769\n",
      "\n",
      "----Iteration 9  ----\n",
      "RF6 accuracy = 0.850035827618\n",
      "RF6 metric report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      <=50K       0.88      0.93      0.90      7431\n",
      "       >50K       0.73      0.59      0.65      2338\n",
      "\n",
      "avg / total       0.84      0.85      0.84      9769\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create an object that holds the third RF model with parameter adjustments\n",
    "\n",
    "RF6 = RandomForestClassifier(max_depth=25, random_state=111)\n",
    "\n",
    "# Now we want to iterate through and grab the prediction, just like we did in the RF4 above\n",
    "iter_num=0\n",
    "# The indices are the rows used for training and testing in each iteration\n",
    "for train_indices, test_indices in sss.split(X,y): \n",
    "    X_train = X[train_indices]  #train indices for X\n",
    "    y_train = y[train_indices]  #train indices for y\n",
    "    \n",
    "    X_test = X[test_indices]    #test indices for X\n",
    "    y_test = y[test_indices]    #test indices for y\n",
    "    \n",
    "    # Train the reusable KNN classifier on the training data\n",
    "    RF6.fit(X_train,y_train)  # train object\n",
    "    y_hat = RF6.predict(X_test) #get the test set predictions \n",
    "    \n",
    "    # Accuracy for the iterations of training/testing\n",
    "    accuracy_RF6= mt.accuracy_score(y_test,y_hat)    # obtain accuracies for each iteration \n",
    "    print(\"----Iteration\",iter_num,\" ----\")          # print out each numbered interation \n",
    "    print('RF6 accuracy =', accuracy_RF6)\n",
    "\n",
    "    # Metric report \n",
    "    metrics_RF6 = classification_report(y_test,y_hat)\n",
    "    print('RF6 metric report')\n",
    "    print(metrics_RF6)\n",
    "    iter_num+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean accuracy for this model is  0.849032654315\n"
     ]
    }
   ],
   "source": [
    "# Get the mean accuracy\n",
    "\n",
    "# Load the accuracies\n",
    "accuracies_RF6 = cross_val_score(RF6, X, y=y, cv=sss) # this also can help with parallelism\n",
    "\n",
    "# Print out the mean \n",
    "mean_RF6 = np.mean(accuracies_RF6)\n",
    "print(\"The mean accuracy for this model is \", mean_RF6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. The mean accuracy for RF model 1 is  0.83975841949\n",
      "------------------------------------------------------------------------\n",
      "2. The mean accuracy for RF model 2 is  0.855113112908\n",
      "------------------------------------------------------------------------\n",
      "3. The mean accuracy for RF model 3 is  0.854273723001\n",
      "------------------------------------------------------------------------\n",
      "4. The mean accuracy for RF model 4 is  0.83975841949\n",
      "------------------------------------------------------------------------\n",
      "5. The mean accuracy for RF model 5 is  0.839615109018\n",
      "------------------------------------------------------------------------\n",
      "6. The mean accuracy for RF model 6 is  0.849032654315\n",
      "------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Accuracies for comparision for each RF model \n",
    "\n",
    "# RF model 1\n",
    "print(\"1. The mean accuracy for RF model 1 is \", mean_RF)\n",
    "print('------------------------------------------------------------------------')\n",
    "\n",
    "# RF model 2\n",
    "print(\"2. The mean accuracy for RF model 2 is \", mean_RF2)\n",
    "print('------------------------------------------------------------------------')\n",
    "\n",
    "# RF model 3\n",
    "print(\"3. The mean accuracy for RF model 3 is \", mean_RF3)\n",
    "print('------------------------------------------------------------------------')\n",
    "\n",
    "# RF model 4\n",
    "print(\"4. The mean accuracy for RF model 4 is \", mean_RF4)\n",
    "print('------------------------------------------------------------------------')\n",
    "\n",
    "# RF model 5\n",
    "print(\"5. The mean accuracy for RF model 5 is \", mean_RF5)\n",
    "print('------------------------------------------------------------------------')\n",
    "\n",
    "# RF model 6\n",
    "print(\"6. The mean accuracy for RF model 6 is \", mean_RF6)\n",
    "print('------------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----Iteration 0  ----\n",
      "RF2 accuracy = 0.853311495547\n",
      "RF2 metric report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      <=50K       0.87      0.95      0.91      7431\n",
      "       >50K       0.77      0.55      0.64      2338\n",
      "\n",
      "avg / total       0.85      0.85      0.84      9769\n",
      "\n",
      "----Iteration 1  ----\n",
      "RF2 accuracy = 0.858532091309\n",
      "RF2 metric report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      <=50K       0.87      0.95      0.91      7431\n",
      "       >50K       0.79      0.55      0.65      2338\n",
      "\n",
      "avg / total       0.85      0.86      0.85      9769\n",
      "\n",
      "----Iteration 2  ----\n",
      "RF2 accuracy = 0.854642235643\n",
      "RF2 metric report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      <=50K       0.87      0.96      0.91      7431\n",
      "       >50K       0.80      0.53      0.63      2338\n",
      "\n",
      "avg / total       0.85      0.85      0.84      9769\n",
      "\n",
      "----Iteration 3  ----\n",
      "RF2 accuracy = 0.851161838469\n",
      "RF2 metric report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      <=50K       0.87      0.95      0.91      7431\n",
      "       >50K       0.77      0.54      0.64      2338\n",
      "\n",
      "avg / total       0.84      0.85      0.84      9769\n",
      "\n",
      "----Iteration 4  ----\n",
      "RF2 accuracy = 0.854949329512\n",
      "RF2 metric report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      <=50K       0.86      0.97      0.91      7431\n",
      "       >50K       0.82      0.51      0.63      2338\n",
      "\n",
      "avg / total       0.85      0.85      0.84      9769\n",
      "\n",
      "----Iteration 5  ----\n",
      "RF2 accuracy = 0.856689528099\n",
      "RF2 metric report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      <=50K       0.86      0.97      0.91      7431\n",
      "       >50K       0.83      0.51      0.63      2338\n",
      "\n",
      "avg / total       0.85      0.86      0.84      9769\n",
      "\n",
      "----Iteration 6  ----\n",
      "RF2 accuracy = 0.855665881871\n",
      "RF2 metric report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      <=50K       0.87      0.96      0.91      7431\n",
      "       >50K       0.80      0.53      0.64      2338\n",
      "\n",
      "avg / total       0.85      0.86      0.84      9769\n",
      "\n",
      "----Iteration 7  ----\n",
      "RF2 accuracy = 0.851673661583\n",
      "RF2 metric report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      <=50K       0.86      0.96      0.91      7431\n",
      "       >50K       0.81      0.50      0.62      2338\n",
      "\n",
      "avg / total       0.85      0.85      0.84      9769\n",
      "\n",
      "----Iteration 8  ----\n",
      "RF2 accuracy = 0.858429726686\n",
      "RF2 metric report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      <=50K       0.87      0.96      0.91      7431\n",
      "       >50K       0.80      0.54      0.65      2338\n",
      "\n",
      "avg / total       0.85      0.86      0.85      9769\n",
      "\n",
      "----Iteration 9  ----\n",
      "RF2 accuracy = 0.856075340362\n",
      "RF2 metric report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      <=50K       0.86      0.96      0.91      7431\n",
      "       >50K       0.81      0.52      0.63      2338\n",
      "\n",
      "avg / total       0.85      0.86      0.84      9769\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create an object that holds the second RF model with parameter adjustments\n",
    "\n",
    "RF2= RandomForestClassifier(max_depth=10, random_state=111)\n",
    "\n",
    "# Now we want to iterate through and grab the prediction, just like we did in the RF above\n",
    "# Now we want to iterate through and grab the prediction, just like we did in the KNN above\n",
    "iter_num=0\n",
    "# the indices are the rows used for training and testing in each iteration\n",
    "for train_indices, test_indices in sss.split(X,y): \n",
    "    X_train = X[train_indices]  # train indices for X\n",
    "    y_train = y[train_indices]  # train indices for y\n",
    "    \n",
    "    X_test = X[test_indices]    # test indices for X\n",
    "    y_test = y[test_indices]    # test indices for y\n",
    "    \n",
    "    # train the reusable KNN classifier on the training data\n",
    "    RF2.fit(X_train,y_train)  # train object\n",
    "    y_hat = RF2.predict(X_test) # get test set precitions\n",
    "    \n",
    "    # Accuracy for the iterations of training/testing\n",
    "    accuracy_RF2 = mt.accuracy_score(y_test,y_hat)   # obtain accuracies for each iteration \n",
    "    print(\"----Iteration\",iter_num,\" ----\")          # print out each numbered interation \n",
    "    print('RF2 accuracy =', accuracy_RF2)\n",
    "\n",
    "    # Metric report \n",
    "    metrics_RF2 = classification_report(y_test,y_hat)\n",
    "    print('RF2 metric report')\n",
    "    print(metrics_RF2)\n",
    "    iter_num+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----Iteration 0  ----\n",
      "RF7 accuracy = 0.856382434231\n",
      "RF7 metric report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      <=50K       0.86      0.96      0.91      7431\n",
      "       >50K       0.81      0.52      0.64      2338\n",
      "\n",
      "avg / total       0.85      0.86      0.84      9769\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TMccw\\Anaconda2\\lib\\site-packages\\sklearn\\ensemble\\forest.py:303: UserWarning: Warm-start fitting without increasing n_estimators does not fit new trees.\n",
      "  warn(\"Warm-start fitting without increasing n_estimators does not \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----Iteration 1  ----\n",
      "RF7 accuracy = 0.864264510185\n",
      "RF7 metric report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      <=50K       0.87      0.96      0.92      7431\n",
      "       >50K       0.83      0.55      0.66      2338\n",
      "\n",
      "avg / total       0.86      0.86      0.85      9769\n",
      "\n",
      "----Iteration 2  ----\n",
      "RF7 accuracy = 0.860988842256\n",
      "RF7 metric report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      <=50K       0.87      0.96      0.91      7431\n",
      "       >50K       0.82      0.54      0.65      2338\n",
      "\n",
      "avg / total       0.86      0.86      0.85      9769\n",
      "\n",
      "----Iteration 3  ----\n",
      "RF7 accuracy = 0.853823318661\n",
      "RF7 metric report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      <=50K       0.86      0.96      0.91      7431\n",
      "       >50K       0.80      0.52      0.63      2338\n",
      "\n",
      "avg / total       0.85      0.85      0.84      9769\n",
      "\n",
      "----Iteration 4  ----\n",
      "RF7 accuracy = 0.860374654519\n",
      "RF7 metric report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      <=50K       0.87      0.96      0.91      7431\n",
      "       >50K       0.82      0.54      0.65      2338\n",
      "\n",
      "avg / total       0.86      0.86      0.85      9769\n",
      "\n",
      "----Iteration 5  ----\n",
      "RF7 accuracy = 0.862729040843\n",
      "RF7 metric report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      <=50K       0.87      0.97      0.91      7431\n",
      "       >50K       0.83      0.54      0.65      2338\n",
      "\n",
      "avg / total       0.86      0.86      0.85      9769\n",
      "\n",
      "----Iteration 6  ----\n",
      "RF7 accuracy = 0.862319582352\n",
      "RF7 metric report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      <=50K       0.87      0.96      0.91      7431\n",
      "       >50K       0.82      0.55      0.66      2338\n",
      "\n",
      "avg / total       0.86      0.86      0.85      9769\n",
      "\n",
      "----Iteration 7  ----\n",
      "RF7 accuracy = 0.855870611117\n",
      "RF7 metric report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      <=50K       0.87      0.96      0.91      7431\n",
      "       >50K       0.80      0.53      0.64      2338\n",
      "\n",
      "avg / total       0.85      0.86      0.84      9769\n",
      "\n",
      "----Iteration 8  ----\n",
      "RF7 accuracy = 0.860477019142\n",
      "RF7 metric report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      <=50K       0.87      0.96      0.91      7431\n",
      "       >50K       0.82      0.54      0.65      2338\n",
      "\n",
      "avg / total       0.86      0.86      0.85      9769\n",
      "\n",
      "----Iteration 9  ----\n",
      "RF7 accuracy = 0.861705394616\n",
      "RF7 metric report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      <=50K       0.87      0.96      0.91      7431\n",
      "       >50K       0.82      0.54      0.65      2338\n",
      "\n",
      "avg / total       0.86      0.86      0.85      9769\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create an object that holds the third RF model with parameter adjustments\n",
    "# The warm_start parameter reuses the solution of the previous model called and adds more estimators\n",
    "\n",
    "RF7 = RandomForestClassifier(max_depth=10, random_state=111, n_estimators=150, warm_start=True)\n",
    "\n",
    "# Now we want to iterate through and grab the prediction, just like we did in the RF2 above\n",
    "iter_num=0\n",
    "# The indices are the rows used for training and testing in each iteration\n",
    "for train_indices, test_indices in sss.split(X,y): \n",
    "    X_train = X[train_indices]  #train indices for X\n",
    "    y_train = y[train_indices]  #train indices for y\n",
    "    \n",
    "    X_test = X[test_indices]    #test indices for X\n",
    "    y_test = y[test_indices]    #test indices for y\n",
    "    \n",
    "    # Train the reusable KNN classifier on the training data\n",
    "    RF7.fit(X_train,y_train)  # train object\n",
    "    y_hat = RF7.predict(X_test) #get the test set predictions \n",
    "    \n",
    "    # Accuracy for the iterations of training/testing\n",
    "    accuracy_RF7= mt.accuracy_score(y_test,y_hat)\n",
    "    print(\"----Iteration\",iter_num,\" ----\")          # print out each numbered interation \n",
    "    print('RF7 accuracy =', accuracy_RF7)\n",
    "\n",
    "    # Metric report \n",
    "    metrics_RF7 = classification_report(y_test,y_hat)\n",
    "    print('RF7 metric report')\n",
    "    print(metrics_RF7)\n",
    "    iter_num+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean accuracy for this model is  0.856771419797\n"
     ]
    }
   ],
   "source": [
    "# Get the mean accuracy\n",
    "\n",
    "# Load the accuracies\n",
    "accuracies_RF7 = cross_val_score(RF7, X, y=y, cv=sss) # this also can help with parallelism\n",
    "\n",
    "# Print out the mean \n",
    "mean_RF7 = np.mean(accuracies_RF7)\n",
    "print(\"The mean accuracy for this model is \", mean_RF7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----Iteration 0  ----\n",
      "RF8 accuracy = 0.856280069608\n",
      "RF8 metric report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      <=50K       0.86      0.96      0.91      7431\n",
      "       >50K       0.81      0.52      0.63      2338\n",
      "\n",
      "avg / total       0.85      0.86      0.84      9769\n",
      "\n",
      "----Iteration 1  ----\n",
      "RF8 accuracy = 0.864366874808\n",
      "RF8 metric report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      <=50K       0.87      0.96      0.92      7431\n",
      "       >50K       0.83      0.55      0.66      2338\n",
      "\n",
      "avg / total       0.86      0.86      0.85      9769\n",
      "\n",
      "----Iteration 2  ----\n",
      "RF8 accuracy = 0.861091206879\n",
      "RF8 metric report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      <=50K       0.87      0.96      0.91      7431\n",
      "       >50K       0.82      0.54      0.65      2338\n",
      "\n",
      "avg / total       0.86      0.86      0.85      9769\n",
      "\n",
      "----Iteration 3  ----\n",
      "RF8 accuracy = 0.853004401679\n",
      "RF8 metric report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      <=50K       0.86      0.96      0.91      7431\n",
      "       >50K       0.80      0.52      0.63      2338\n",
      "\n",
      "avg / total       0.85      0.85      0.84      9769\n",
      "\n",
      "----Iteration 4  ----\n",
      "RF8 accuracy = 0.860272289897\n",
      "RF8 metric report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      <=50K       0.87      0.96      0.91      7431\n",
      "       >50K       0.82      0.54      0.65      2338\n",
      "\n",
      "avg / total       0.86      0.86      0.85      9769\n",
      "\n",
      "----Iteration 5  ----\n",
      "RF8 accuracy = 0.862933770089\n",
      "RF8 metric report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      <=50K       0.87      0.97      0.91      7431\n",
      "       >50K       0.83      0.54      0.65      2338\n",
      "\n",
      "avg / total       0.86      0.86      0.85      9769\n",
      "\n",
      "----Iteration 6  ----\n",
      "RF8 accuracy = 0.862114853107\n",
      "RF8 metric report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      <=50K       0.87      0.96      0.91      7431\n",
      "       >50K       0.82      0.55      0.65      2338\n",
      "\n",
      "avg / total       0.86      0.86      0.85      9769\n",
      "\n",
      "----Iteration 7  ----\n",
      "RF8 accuracy = 0.855461152626\n",
      "RF8 metric report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      <=50K       0.86      0.96      0.91      7431\n",
      "       >50K       0.80      0.52      0.63      2338\n",
      "\n",
      "avg / total       0.85      0.86      0.84      9769\n",
      "\n",
      "----Iteration 8  ----\n",
      "RF8 accuracy = 0.860067560651\n",
      "RF8 metric report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      <=50K       0.87      0.96      0.91      7431\n",
      "       >50K       0.82      0.54      0.65      2338\n",
      "\n",
      "avg / total       0.86      0.86      0.85      9769\n",
      "\n",
      "----Iteration 9  ----\n",
      "RF8 accuracy = 0.862012488484\n",
      "RF8 metric report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      <=50K       0.87      0.96      0.91      7431\n",
      "       >50K       0.83      0.54      0.65      2338\n",
      "\n",
      "avg / total       0.86      0.86      0.85      9769\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create an object that holds the third RF model with parameter adjustments\n",
    "# The warm_start parameter reuses the solution of the previous model called and adds more estimators\n",
    "\n",
    "RF8 = RandomForestClassifier(max_depth=10, random_state=111, n_estimators=200, warm_start=True)\n",
    "\n",
    "# Now we want to iterate through and grab the prediction, just like we did in the RF2 above\n",
    "iter_num=0\n",
    "# The indices are the rows used for training and testing in each iteration\n",
    "for train_indices, test_indices in sss.split(X,y): \n",
    "    X_train = X[train_indices]  #train indices for X\n",
    "    y_train = y[train_indices]  #train indices for y\n",
    "    \n",
    "    X_test = X[test_indices]    #test indices for X\n",
    "    y_test = y[test_indices]    #test indices for y\n",
    "    \n",
    "    # Train the reusable KNN classifier on the training data\n",
    "    RF8.fit(X_train,y_train)  # train object\n",
    "    y_hat = RF8.predict(X_test) #get the test set predictions \n",
    "    \n",
    "    # Accuracy for the iterations of training/testing\n",
    "    accuracy_RF8= mt.accuracy_score(y_test,y_hat)\n",
    "    print(\"----Iteration\",iter_num,\" ----\")          # print out each numbered interation \n",
    "    print('RF8 accuracy =', accuracy_RF8)\n",
    "\n",
    "    # Metric report \n",
    "    metrics_RF8 = classification_report(y_test,y_hat)\n",
    "    print('RF8 metric report')\n",
    "    print(metrics_RF8)\n",
    "    iter_num+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean accuracy for this model is  0.85664858225\n"
     ]
    }
   ],
   "source": [
    "# Get the mean accuracy\n",
    "\n",
    "# Load the accuracies\n",
    "accuracies_RF8 = cross_val_score(RF8, X, y=y, cv=sss) # this also can help with parallelism\n",
    "\n",
    "# Print out the mean \n",
    "mean_RF8 = np.mean(accuracies_RF8)\n",
    "print(\"The mean accuracy for this model is \", mean_RF8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. The mean accuracy for RF model 1 is  0.83975841949\n",
      "------------------------------------------------------------------------\n",
      "2. The mean accuracy for RF model 2 is  0.855113112908\n",
      "------------------------------------------------------------------------\n",
      "3. The mean accuracy for RF model 3 is  0.854273723001\n",
      "------------------------------------------------------------------------\n",
      "4. The mean accuracy for RF model 4 is  0.83975841949\n",
      "------------------------------------------------------------------------\n",
      "5. The mean accuracy for RF model 5 is  0.839615109018\n",
      "------------------------------------------------------------------------\n",
      "6. The mean accuracy for RF model 6 is  0.849032654315\n",
      "------------------------------------------------------------------------\n",
      "7. The mean accuracy for RF model 7 is  0.856771419797\n",
      "------------------------------------------------------------------------\n",
      "8. The mean accuracy for RF model 8 is  0.85664858225\n",
      "------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Accuracies for comparision for each RF model \n",
    "\n",
    "# RF model 1\n",
    "print(\"1. The mean accuracy for RF model 1 is \", mean_RF)\n",
    "print('------------------------------------------------------------------------')\n",
    "\n",
    "# RF model 2\n",
    "print(\"2. The mean accuracy for RF model 2 is \", mean_RF2)\n",
    "print('------------------------------------------------------------------------')\n",
    "\n",
    "# RF model 3\n",
    "print(\"3. The mean accuracy for RF model 3 is \", mean_RF3)\n",
    "print('------------------------------------------------------------------------')\n",
    "\n",
    "# RF model 4\n",
    "print(\"4. The mean accuracy for RF model 4 is \", mean_RF4)\n",
    "print('------------------------------------------------------------------------')\n",
    "\n",
    "# RF model 5\n",
    "print(\"5. The mean accuracy for RF model 5 is \", mean_RF5)\n",
    "print('------------------------------------------------------------------------')\n",
    "\n",
    "# RF model 6\n",
    "print(\"6. The mean accuracy for RF model 6 is \", mean_RF6)\n",
    "print('------------------------------------------------------------------------')\n",
    "\n",
    "# RF model 7\n",
    "print(\"7. The mean accuracy for RF model 7 is \", mean_RF7)\n",
    "print('------------------------------------------------------------------------')\n",
    "\n",
    "# RF model 8\n",
    "print(\"8. The mean accuracy for RF model 8 is \", mean_RF8)\n",
    "print('------------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Random Forest model with the highest predicted accuracy is model 7. Random Forest model 7 has a max tree depth of 10 and 150 estimators, which represents the number of trees in the forest. We have also included the *warm_start* hyperparameter to this model. This hyperparameter reuses the solution of the previous model called, which was RF model 2, and adds more estimators. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=10, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=150, n_jobs=1, oob_score=False, random_state=111,\n",
      "            verbose=0, warm_start=True)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nNcKELkmNMKFLUiNM6JLUiP8H0CIA3Hcl1qkAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xc595208>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print (RF7)\n",
    "\n",
    "plt.barh(range(len(RF7.feature_importances_)), RF7.feature_importances_)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Naive Bayes classification for *income_binary*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----Iteration 0  ----\n",
      "GNB accuracy = 0.768655952503\n",
      "GNB metric report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      <=50K       0.95      0.74      0.83      7431\n",
      "       >50K       0.51      0.86      0.64      2338\n",
      "\n",
      "avg / total       0.84      0.77      0.78      9769\n",
      "\n",
      "----Iteration 1  ----\n",
      "GNB accuracy = 0.767018118538\n",
      "GNB metric report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      <=50K       0.95      0.74      0.83      7431\n",
      "       >50K       0.51      0.87      0.64      2338\n",
      "\n",
      "avg / total       0.84      0.77      0.78      9769\n",
      "\n",
      "----Iteration 2  ----\n",
      "GNB accuracy = 0.759136042584\n",
      "GNB metric report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      <=50K       0.94      0.73      0.82      7431\n",
      "       >50K       0.50      0.85      0.63      2338\n",
      "\n",
      "avg / total       0.83      0.76      0.78      9769\n",
      "\n",
      "----Iteration 3  ----\n",
      "GNB accuracy = 0.769474869485\n",
      "GNB metric report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      <=50K       0.95      0.74      0.83      7431\n",
      "       >50K       0.51      0.86      0.64      2338\n",
      "\n",
      "avg / total       0.84      0.77      0.79      9769\n",
      "\n",
      "----Iteration 4  ----\n",
      "GNB accuracy = 0.77111270345\n",
      "GNB metric report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      <=50K       0.95      0.74      0.83      7431\n",
      "       >50K       0.51      0.87      0.64      2338\n",
      "\n",
      "avg / total       0.84      0.77      0.79      9769\n",
      "\n",
      "----Iteration 5  ----\n",
      "GNB accuracy = 0.772648172791\n",
      "GNB metric report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      <=50K       0.95      0.74      0.83      7431\n",
      "       >50K       0.51      0.87      0.65      2338\n",
      "\n",
      "avg / total       0.84      0.77      0.79      9769\n",
      "\n",
      "----Iteration 6  ----\n",
      "GNB accuracy = 0.764766096837\n",
      "GNB metric report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      <=50K       0.94      0.73      0.83      7431\n",
      "       >50K       0.51      0.86      0.64      2338\n",
      "\n",
      "avg / total       0.84      0.76      0.78      9769\n",
      "\n",
      "----Iteration 7  ----\n",
      "GNB accuracy = 0.763435356741\n",
      "GNB metric report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      <=50K       0.94      0.74      0.83      7431\n",
      "       >50K       0.50      0.85      0.63      2338\n",
      "\n",
      "avg / total       0.84      0.76      0.78      9769\n",
      "\n",
      "----Iteration 8  ----\n",
      "GNB accuracy = 0.760773876548\n",
      "GNB metric report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      <=50K       0.95      0.73      0.82      7431\n",
      "       >50K       0.50      0.87      0.63      2338\n",
      "\n",
      "avg / total       0.84      0.76      0.78      9769\n",
      "\n",
      "----Iteration 9  ----\n",
      "GNB accuracy = 0.761695158153\n",
      "GNB metric report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      <=50K       0.94      0.73      0.82      7431\n",
      "       >50K       0.50      0.86      0.63      2338\n",
      "\n",
      "avg / total       0.84      0.76      0.78      9769\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create an object that holds the NB\n",
    "\n",
    "GNB = GaussianNB()\n",
    "\n",
    "# Now we want to iterate through and grab the prediction, just like we did in the RF2 above\n",
    "iter_num=0\n",
    "# The indices are the rows used for training and testing in each iteration\n",
    "for train_indices, test_indices in sss.split(X,y): \n",
    "    X_train = X[train_indices]  #train indices for X\n",
    "    y_train = y[train_indices]  #train indices for y\n",
    "    \n",
    "    X_test = X[test_indices]    #test indices for X\n",
    "    y_test = y[test_indices]    #test indices for y\n",
    "    \n",
    "    # Train the reusable KNN classifier on the training data\n",
    "    GNB.fit(X_train,y_train)  # train object\n",
    "    y_hat = GNB.predict(X_test) #get the test set predictions \n",
    "    \n",
    "    # Accuracy for the iterations of training/testing\n",
    "    accuracy_GNB= mt.accuracy_score(y_test,y_hat)\n",
    "    print(\"----Iteration\",iter_num,\" ----\")          # print out each numbered interation \n",
    "    print('GNB accuracy =', accuracy_GNB)\n",
    "\n",
    "    # Metric report \n",
    "    metrics_GNB = classification_report(y_test,y_hat)\n",
    "    print('GNB metric report')\n",
    "    print(metrics_GNB)\n",
    "    iter_num+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean accuracy for this model is  0.765871634763\n"
     ]
    }
   ],
   "source": [
    "# Get the mean accuracy\n",
    "\n",
    "# Load the accuracies\n",
    "accuracies_GNB = cross_val_score(GNB, X, y=y, cv=sss) # this also can help with parallelism\n",
    "\n",
    "# Print out the mean \n",
    "mean_GNB = np.mean(accuracies_GNB)\n",
    "print(\"The mean accuracy for this model is \", mean_GNB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----Iteration 0  ----\n",
      "BNB accuracy = 0.744088443034\n",
      "BNB metric report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      <=50K       0.92      0.73      0.81      7431\n",
      "       >50K       0.48      0.79      0.60      2338\n",
      "\n",
      "avg / total       0.81      0.74      0.76      9769\n",
      "\n",
      "----Iteration 1  ----\n",
      "BNB accuracy = 0.750127955778\n",
      "BNB metric report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      <=50K       0.92      0.73      0.82      7431\n",
      "       >50K       0.49      0.81      0.61      2338\n",
      "\n",
      "avg / total       0.82      0.75      0.77      9769\n",
      "\n",
      "----Iteration 2  ----\n",
      "BNB accuracy = 0.742348244447\n",
      "BNB metric report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      <=50K       0.91      0.73      0.81      7431\n",
      "       >50K       0.48      0.78      0.59      2338\n",
      "\n",
      "avg / total       0.81      0.74      0.76      9769\n",
      "\n",
      "----Iteration 3  ----\n",
      "BNB accuracy = 0.748490121814\n",
      "BNB metric report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      <=50K       0.92      0.73      0.82      7431\n",
      "       >50K       0.48      0.80      0.60      2338\n",
      "\n",
      "avg / total       0.82      0.75      0.76      9769\n",
      "\n",
      "----Iteration 4  ----\n",
      "BNB accuracy = 0.751049237384\n",
      "BNB metric report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      <=50K       0.92      0.74      0.82      7431\n",
      "       >50K       0.49      0.80      0.61      2338\n",
      "\n",
      "avg / total       0.82      0.75      0.77      9769\n",
      "\n",
      "----Iteration 5  ----\n",
      "BNB accuracy = 0.751356331252\n",
      "BNB metric report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      <=50K       0.92      0.74      0.82      7431\n",
      "       >50K       0.49      0.80      0.61      2338\n",
      "\n",
      "avg / total       0.82      0.75      0.77      9769\n",
      "\n",
      "----Iteration 6  ----\n",
      "BNB accuracy = 0.748387757191\n",
      "BNB metric report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      <=50K       0.92      0.73      0.82      7431\n",
      "       >50K       0.48      0.80      0.60      2338\n",
      "\n",
      "avg / total       0.82      0.75      0.76      9769\n",
      "\n",
      "----Iteration 7  ----\n",
      "BNB accuracy = 0.747568840209\n",
      "BNB metric report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      <=50K       0.92      0.73      0.82      7431\n",
      "       >50K       0.48      0.80      0.60      2338\n",
      "\n",
      "avg / total       0.81      0.75      0.76      9769\n",
      "\n",
      "----Iteration 8  ----\n",
      "BNB accuracy = 0.740505681237\n",
      "BNB metric report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      <=50K       0.92      0.72      0.81      7431\n",
      "       >50K       0.47      0.79      0.59      2338\n",
      "\n",
      "avg / total       0.81      0.74      0.76      9769\n",
      "\n",
      "----Iteration 9  ----\n",
      "BNB accuracy = 0.748490121814\n",
      "BNB metric report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      <=50K       0.92      0.73      0.82      7431\n",
      "       >50K       0.48      0.79      0.60      2338\n",
      "\n",
      "avg / total       0.81      0.75      0.76      9769\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create an object that holds the BNB classifier. \n",
    "# BernoulliNB is used because it is desgined for binary features\n",
    "\n",
    "BNB = BernoulliNB()\n",
    "\n",
    "# Now we want to iterate through and grab the prediction, just like we did in the RF2 above\n",
    "iter_num=0\n",
    "# The indices are the rows used for training and testing in each iteration\n",
    "for train_indices, test_indices in sss.split(X,y): \n",
    "    X_train = X[train_indices]  #train indices for X\n",
    "    y_train = y[train_indices]  #train indices for y\n",
    "    \n",
    "    X_test = X[test_indices]    #test indices for X\n",
    "    y_test = y[test_indices]    #test indices for y\n",
    "    \n",
    "    # Train the reusable KNN classifier on the training data\n",
    "    BNB.fit(X_train,y_train)  # train object\n",
    "    y_hat = BNB.predict(X_test) #get the test set predictions \n",
    "    \n",
    "    # Accuracy for the iterations of training/testing\n",
    "    accuracy_BNB= mt.accuracy_score(y_test,y_hat)\n",
    "    print(\"----Iteration\",iter_num,\" ----\")          # print out each numbered interation \n",
    "    print('BNB accuracy =', accuracy_BNB)\n",
    "\n",
    "    # Metric report \n",
    "    metrics_BNB = classification_report(y_test,y_hat)\n",
    "    print('BNB metric report')\n",
    "    print(metrics_BNB)\n",
    "    iter_num+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean accuracy for this model is  0.747241273416\n"
     ]
    }
   ],
   "source": [
    "# Get the mean accuracy\n",
    "\n",
    "# Load the accuracies\n",
    "accuracies_BNB = cross_val_score(BNB, X, y=y, cv=sss) # this also can help with parallelism\n",
    "\n",
    "# Print out the mean \n",
    "mean_BNB = np.mean(accuracies_BNB)\n",
    "print(\"The mean accuracy for this model is \", mean_BNB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. The mean accuracy for GNB model 1 is  0.765871634763\n",
      "------------------------------------------------------------------------\n",
      "1. The mean accuracy for BNB model 1 is  0.747241273416\n",
      "------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Accuracy, Precision, Rcall, and F-score for comparision for each NB  \n",
    "\n",
    "# GNB \n",
    "print(\"1. The mean accuracy for GNB model 1 is \", mean_GNB)\n",
    "print('------------------------------------------------------------------------')\n",
    "\n",
    "# BNB\n",
    "print(\"1. The mean accuracy for BNB model 1 is \", mean_BNB)\n",
    "print('------------------------------------------------------------------------')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "For the Naive Bayes classifier, we are going to use the Bernoulli model because Bernoulli models are mainly used for classifying binary data. Even though the Gaussian model has a slightly higher accuracy, the Bernoulli is the correct model to choose for our given data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing K-Nearest Neighbor, Random Forest, and Naive Bayes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. The mean accuracy for KNN model is  0.835510287645\n",
      "------------------------------------------------------------------------\n",
      "2. The mean accuracy for RF model 7 is  0.856771419797\n",
      "------------------------------------------------------------------------\n",
      "3. The mean accuracy for BNB model 1 is  0.747241273416\n",
      "------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Mean accuracies for the three different classification methods\n",
    "\n",
    "# KNN model 1\n",
    "print(\"1. The mean accuracy for KNN model is \", mean_KNN)\n",
    "print('------------------------------------------------------------------------')\n",
    "\n",
    "# RF model 7\n",
    "print(\"2. The mean accuracy for RF model 7 is \", mean_RF7)\n",
    "print('------------------------------------------------------------------------')\n",
    "\n",
    "# BNB\n",
    "print(\"3. The mean accuracy for BNB model 1 is \", mean_BNB)\n",
    "print('------------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Random Forest classifier has the highest mean predicted accuracy, 85.67%, when compared to the other two classification methods. K-Nearest Neighbor has the second highest mean predicted accuracy, 83.55%, while Bernoulli Navie Bayes classifier has the lowest mean predicted accuracy, 74.72%. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statistical Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interpertation of the Confidence Interval \n",
    "\n",
    "We are 95% confident that the mean of the three models is between [-0.4352, -0.0279]. The interval does not include 0. This means that there is a significant difference between the three models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----Iteration 0  ----\n",
      "KNN Error Rate = 16.47\n",
      "----Iteration 1  ----\n",
      "KNN Error Rate = 16.07\n",
      "----Iteration 2  ----\n",
      "KNN Error Rate = 16.69\n",
      "----Iteration 3  ----\n",
      "KNN Error Rate = 16.93\n",
      "----Iteration 4  ----\n",
      "KNN Error Rate = 16.7\n",
      "----Iteration 5  ----\n",
      "KNN Error Rate = 16.44\n",
      "----Iteration 6  ----\n",
      "KNN Error Rate = 16.22\n",
      "----Iteration 7  ----\n",
      "KNN Error Rate = 16.66\n",
      "----Iteration 8  ----\n",
      "KNN Error Rate = 16.25\n",
      "----Iteration 9  ----\n",
      "KNN Error Rate = 16.12\n",
      "----Iteration 0  ----\n",
      "RF Error Rate = 14.37\n",
      "----Iteration 1  ----\n",
      "RF Error Rate = 13.58\n",
      "----Iteration 2  ----\n",
      "RF Error Rate = 13.91\n",
      "----Iteration 3  ----\n",
      "RF Error Rate = 14.62\n",
      "----Iteration 4  ----\n",
      "RF Error Rate = 13.97\n",
      "----Iteration 5  ----\n",
      "RF Error Rate = 13.73\n",
      "----Iteration 6  ----\n",
      "RF Error Rate = 13.77\n",
      "----Iteration 7  ----\n",
      "RF Error Rate = 14.42\n",
      "----Iteration 8  ----\n",
      "RF Error Rate = 13.96\n",
      "----Iteration 9  ----\n",
      "RF Error Rate = 13.83\n",
      "----Iteration 0  ----\n",
      "BNB Error Rate = 25.6\n",
      "----Iteration 1  ----\n",
      "BNB Error Rate = 24.99\n",
      "----Iteration 2  ----\n",
      "BNB Error Rate = 25.77\n",
      "----Iteration 3  ----\n",
      "BNB Error Rate = 25.16\n",
      "----Iteration 4  ----\n",
      "BNB Error Rate = 24.9\n",
      "----Iteration 5  ----\n",
      "BNB Error Rate = 24.87\n",
      "----Iteration 6  ----\n",
      "BNB Error Rate = 25.17\n",
      "----Iteration 7  ----\n",
      "BNB Error Rate = 25.25\n",
      "----Iteration 8  ----\n",
      "BNB Error Rate = 25.95\n",
      "----Iteration 9  ----\n",
      "BNB Error Rate = 25.16\n"
     ]
    }
   ],
   "source": [
    "# Calculating the Error Rates of the three models \n",
    "\n",
    "# KNN Model\n",
    "KNN_Accs = [83.53, 83.93, 83.31, 83.07, 83.30, 83.56, 83.78, 83.34, 83.75, 83.88]\n",
    "\n",
    "iter_num=0\n",
    "for x in KNN_Accs:\n",
    "    KNN_ER = 100-x\n",
    "    print(\"----Iteration\",iter_num,\" ----\") \n",
    "    print('KNN Error Rate =', KNN_ER)\n",
    "    iter_num+=1\n",
    "\n",
    "# RF Model \n",
    "RF_Accs = [85.63, 86.42, 86.09, 85.38, 86.03, 86.27, 86.23, 85.58, 86.04, 86.17]\n",
    "\n",
    "iter_num=0\n",
    "for x in RF_Accs:\n",
    "    RF_ER = 100-x\n",
    "    print(\"----Iteration\",iter_num,\" ----\") \n",
    "    print('RF Error Rate =', RF_ER)\n",
    "    iter_num+=1\n",
    "    \n",
    "# BNB Model \n",
    "BNB_Accs = [74.40, 75.01, 74.23, 74.84, 75.10, 75.13, 74.83, 74.75, 74.05, 74.84]\n",
    "\n",
    "iter_num=0\n",
    "for x in BNB_Accs:\n",
    "    BNB_ER = 100-x\n",
    "    print(\"----Iteration\",iter_num,\" ----\") \n",
    "    print('BNB Error Rate =', BNB_ER)\n",
    "    iter_num+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2.1   2.49  2.78  2.31  2.73  2.71  2.45  2.24  2.29  2.29]\n",
      "[-9.13 -8.92 -9.08 -8.23 -8.2  -8.43 -8.95 -8.59 -9.7  -9.04]\n",
      "[-11.23 -11.41 -11.86 -10.54 -10.93 -11.14 -11.4  -10.83 -11.99 -11.33]\n"
     ]
    }
   ],
   "source": [
    "# Calculate the difference in the error rate bewteen each model comparsion\n",
    "KNN_ER = np.array([16.47, 16.07, 16.69, 16.93, 16.7, 16.44, 16.22, 16.66, 16.25, 16.12])\n",
    "RF_ER = np.array([14.37, 13.58, 13.91, 14.62, 13.97, 13.73, 13.77, 14.42, 13.96, 13.83])\n",
    "BNB_ER = np.array([25.6, 24.99, 25.77, 25.16, 24.9, 24.87, 25.17, 25.25, 25.95, 25.16])\n",
    "\n",
    "# KNN to RF \n",
    "Diff1 = KNN_ER - RF_ER\n",
    "print(Diff1)\n",
    "\n",
    "# KNN to BNB\n",
    "Diff2 = KNN_ER - BNB_ER\n",
    "print(Diff2)\n",
    "\n",
    "# RF to BNB\n",
    "Diff3 = RF_ER - BNB_ER\n",
    "print(Diff3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.439\n",
      "-8.827\n",
      "-11.266\n"
     ]
    }
   ],
   "source": [
    "# Calculate the mean of the differance in Error Rates for each model comparison\n",
    "\n",
    "# KNN to RF \n",
    "mean1 = np.mean(Diff1)\n",
    "print(mean1)\n",
    "\n",
    "# KNN to BNB\n",
    "mean2 = np.mean(Diff2)\n",
    "print(mean2)\n",
    "\n",
    "# RF to BNB\n",
    "mean3 = np.mean(Diff3)\n",
    "print(mean3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variance for KNN & RF = 0.149\n",
      "Variance for KNN & BNB = 0.213\n",
      "Variance for RF & BNB = 0.064\n"
     ]
    }
   ],
   "source": [
    "# Calculate the Variance of the differance in Error Rates for each model comparison\n",
    "K = 10 \n",
    "\n",
    "# KNN to RF \n",
    "for x in Diff1:\n",
    "    y = x-mean1\n",
    "    #print(y)\n",
    "\n",
    "sumy = np.sum(y)\n",
    "# print(sumy)\n",
    "\n",
    "V = (1/K-1)*(sumy)\n",
    "print('Variance for KNN & RF =', V)\n",
    "\n",
    "# KNN to BNB\n",
    "for x in Diff2:\n",
    "    y2 = x-mean2\n",
    "    #print(y)\n",
    "\n",
    "sumy2 = np.sum(y2)\n",
    "# print(sumy)\n",
    "\n",
    "V2 = (1/K-1)*(sumy2)\n",
    "print('Variance for KNN & BNB =', V2)\n",
    "\n",
    "# RF to BNB\n",
    "for x in Diff3:\n",
    "    y3 = x-mean3\n",
    "    #print(y)\n",
    "\n",
    "sumy3 = np.sum(y3)\n",
    "# print(sumy)\n",
    "\n",
    "V3 = (1/K-1)*(sumy3)\n",
    "print('Variance for RF & BNB =', V3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confidence Interval for KNN and RF is 2.35362229791 2.52437770209\n"
     ]
    }
   ],
   "source": [
    "# Calculate the Confidence Intervals for each comparison\n",
    "K = 10\n",
    "t_stat = 1.812\n",
    "\n",
    "# KNN to RF\n",
    "l = 1/math.sqrt(K)*t_stat*V\n",
    "\n",
    "CI_plus = mean1 + l\n",
    "CI_minus = mean1 - l\n",
    "print('Confidence Interval for KNN and RF is', CI_minus, CI_plus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0853777020914\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
