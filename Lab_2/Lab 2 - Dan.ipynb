{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Imports for data-preprocessing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from __future__ import print_function\n",
    "\n",
    "# Import for spliting the data set\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Imports for classificaiton \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.decomposition import PCA \n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import metrics as mt\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import data\n",
    "df = pd.read_csv('../data/master.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bins = [17, 34, 49, 64, 90]\n",
    "\n",
    "group_names = ['17-34', '35-49', '50-64', '65+']\n",
    "\n",
    "age_groups = pd.cut(df.age, bins, labels=group_names)\n",
    "\n",
    "df['age_groups'] = age_groups.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Delete unwanted variables\n",
    "del df['workclass']\n",
    "del df['education']\n",
    "del df['education_num']\n",
    "del df['marital_status']\n",
    "del df['occupation']\n",
    "del df['native_country'] \n",
    "del df['age']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split the data into traning (80%) and test set (20%)\n",
    "# We are using stratified cross validation here because the majority of the\n",
    "#    individuals in the variable race are white\n",
    "\n",
    "if 'age_groups' in df:\n",
    "    y = df['age_groups'] #get values we need \n",
    "    del df['age_groups']        #get rid of the class label\n",
    "    X = df.values                  #use everything else to predict \n",
    "    \n",
    "X = pd.get_dummies(df).values\n",
    "\n",
    "scl = StandardScaler()\n",
    "# X = scl.fit_transform(X)\n",
    "\n",
    "# Split the data into 20% Test and 80% Train\n",
    "sss = StratifiedShuffleSplit(n_splits=10, test_size=0.20, random_state=111)\n",
    "sss.get_n_splits(X, y) #retreving the splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: [ 8492   773 13118 ..., 35980 33511 35588] TEST: [19692 27047 14102 ...,  5491 27134 25133]\n",
      "TRAIN: [35754 44603 33516 ...,  9966 39949 27930] TEST: [ 6576 30339 39221 ..., 26307 20282 14216]\n",
      "TRAIN: [ 9692 36813  2848 ..., 16610 48026 24110] TEST: [17088 44904 33742 ..., 39410 34564 24713]\n",
      "TRAIN: [18717 17405 28960 ..., 17899 20181 28803] TEST: [29770  5237 39991 ..., 19858 25079 39382]\n",
      "TRAIN: [31784 43606 33743 ..., 43070 11410 40058] TEST: [ 5991  5420 37845 ..., 23131 38821 38455]\n",
      "TRAIN: [10324 22662 46232 ..., 13002  5850 47428] TEST: [35217 41009 45992 ..., 19937 37685 43961]\n",
      "TRAIN: [10245 34540 19934 ...,  4642 48455  1175] TEST: [46966 10993 27579 ..., 31110 48759 43327]\n",
      "TRAIN: [39885  4332  3592 ..., 44157 11660 46607] TEST: [31259 23034  5609 ..., 20253 24091 12492]\n",
      "TRAIN: [17705 32836 34332 ..., 30752 31903 12175] TEST: [24823 12082 42233 ..., 14850 38281 46484]\n",
      "TRAIN: [ 9054 18693 13929 ...,  8118 28501 10876] TEST: [37717 40166 28516 ...,  4861 47589  9591]\n"
     ]
    }
   ],
   "source": [
    "# y = y.fillna(\"\")\n",
    "\n",
    "# for train_index, test_index in sss.split(X,y.tolist()):\n",
    "#     print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "#     X_train, X_test = X[train_index], X[test_index]\n",
    "#     y_train, y_test = y[train_index], y[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'>' not supported between instances of 'float' and 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-149bf164f2a4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpenalty\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'l2'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mC\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1.0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mrfe\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRFE\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mfit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrfe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Users\\dmf42\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\rfe.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    133\u001b[0m             \u001b[0mThe\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    134\u001b[0m         \"\"\"\n\u001b[1;32m--> 135\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    136\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    137\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstep_score\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\dmf42\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\rfe.py\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, X, y, step_score)\u001b[0m\n\u001b[0;32m    167\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Fitting estimator with %d features.\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msupport_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    168\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 169\u001b[1;33m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    170\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    171\u001b[0m             \u001b[1;31m# Get coefs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\dmf42\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1172\u001b[0m         X, y = check_X_y(X, y, accept_sparse='csr', dtype=np.float64,\n\u001b[0;32m   1173\u001b[0m                          order=\"C\")\n\u001b[1;32m-> 1174\u001b[1;33m         \u001b[0mcheck_classification_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1175\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1176\u001b[0m         \u001b[0mn_samples\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\dmf42\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\multiclass.py\u001b[0m in \u001b[0;36mcheck_classification_targets\u001b[1;34m(y)\u001b[0m\n\u001b[0;32m    167\u001b[0m     \u001b[0my\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mlike\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    168\u001b[0m     \"\"\"\n\u001b[1;32m--> 169\u001b[1;33m     \u001b[0my_type\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    170\u001b[0m     if y_type not in ['binary', 'multiclass', 'multiclass-multioutput',\n\u001b[0;32m    171\u001b[0m             'multilabel-indicator', 'multilabel-sequences']:\n",
      "\u001b[1;32mC:\\Users\\dmf42\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\multiclass.py\u001b[0m in \u001b[0;36mtype_of_target\u001b[1;34m(y)\u001b[0m\n\u001b[0;32m    273\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[1;34m'continuous'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msuffix\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    274\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 275\u001b[1;33m     \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    276\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[1;34m'multiclass'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msuffix\u001b[0m  \u001b[1;31m# [1, 2, 3] or [[1., 2., 3]] or [[1, 2]]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    277\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\dmf42\\Anaconda3\\lib\\site-packages\\numpy\\lib\\arraysetops.py\u001b[0m in \u001b[0;36munique\u001b[1;34m(ar, return_index, return_inverse, return_counts)\u001b[0m\n\u001b[0;32m    212\u001b[0m         \u001b[0maux\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mar\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mperm\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    213\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 214\u001b[1;33m         \u001b[0mar\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    215\u001b[0m         \u001b[0maux\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mar\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    216\u001b[0m     \u001b[0mflag\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maux\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0maux\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: '>' not supported between instances of 'float' and 'str'"
     ]
    }
   ],
   "source": [
    "y = y.fillna(\"\")\n",
    "model = LogisticRegression(penalty='l2', C=1.0)\n",
    "rfe = RFE(model, 10)\n",
    "fit = rfe.fit(X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num Features: 10\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'columns'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-51-1d8cdee8dc8d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[1;32mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Num Features:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_features_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mfeatures\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msupport_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[1;32mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Selected Features: \\n\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m==\u001b[0m\u001b[0mTrue\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[1;32mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Feature Ranking:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mranking_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'columns'"
     ]
    }
   ],
   "source": [
    "# print(\"Num Features:\", fit.n_features_)\n",
    "# features = pd.Series(fit.support_, index=X.columns)\n",
    "# print(\"Selected Features: \\n\", features[features==True])\n",
    "# print(\"Feature Ranking:\", fit.ranking_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====Iteration 0  ====\n",
      "accuracy 0.573241887604\n",
      "confusion matrix\n",
      " [[   0  117    1    0    1]\n",
      " [   0 2666 1404    9    4]\n",
      " [   0  617 2744   53   18]\n",
      " [   0  175 1373  128   42]\n",
      " [   0   67  231   57   62]]\n",
      "====Iteration 1  ====\n",
      "accuracy 0.571911147507\n",
      "confusion matrix\n",
      " [[   0  119    0    0    0]\n",
      " [   0 2647 1425   10    1]\n",
      " [   0  619 2749   54   10]\n",
      " [   0  185 1365  147   21]\n",
      " [   0   52  230   91   44]]\n",
      "====Iteration 2  ====\n",
      "accuracy 0.563824342307\n",
      "confusion matrix\n",
      " [[   0  118    0    1    0]\n",
      " [   0 2607 1364  112    0]\n",
      " [   0  616 2650  164    2]\n",
      " [   0  142 1329  243    4]\n",
      " [   0   32  227  150    8]]\n",
      "====Iteration 3  ====\n",
      "accuracy 0.565155082404\n",
      "confusion matrix\n",
      " [[   0  119    0    0    0]\n",
      " [   0 2631 1436   11    5]\n",
      " [   0  664 2707   52    9]\n",
      " [   0  178 1375  138   27]\n",
      " [   0   60  206  106   45]]\n",
      "====Iteration 4  ====\n",
      "accuracy 0.572218241376\n",
      "confusion matrix\n",
      " [[   0  119    0    0    0]\n",
      " [   0 2682 1385   10    6]\n",
      " [   0  656 2707   49   20]\n",
      " [   0  181 1353  138   46]\n",
      " [   0   68  210   76   63]]\n",
      "====Iteration 5  ====\n",
      "accuracy 0.561777049852\n",
      "confusion matrix\n",
      " [[   0  116    2    0    1]\n",
      " [   0 2548 1510   19    6]\n",
      " [   0  616 2735   70   11]\n",
      " [   0  154 1382  161   21]\n",
      " [   0   68  218   87   44]]\n",
      "====Iteration 6  ====\n",
      "accuracy 0.56208414372\n",
      "confusion matrix\n",
      " [[   0  117    2    0    0]\n",
      " [   0 2590 1473   14    6]\n",
      " [   0  666 2694   64    8]\n",
      " [   0  163 1370  161   24]\n",
      " [   0   70  205   96   46]]\n",
      "====Iteration 7  ====\n",
      "accuracy 0.559115569659\n",
      "confusion matrix\n",
      " [[   0  119    0    0    0]\n",
      " [   0 2575 1487   15    6]\n",
      " [   0  688 2680   49   15]\n",
      " [   0  197 1343  139   39]\n",
      " [   0   61  199   89   68]]\n",
      "====Iteration 8  ====\n",
      "accuracy 0.568123656464\n",
      "confusion matrix\n",
      " [[   0  118    1    0    0]\n",
      " [   0 2634 1431   10    8]\n",
      " [   0  652 2714   57    9]\n",
      " [   0  162 1383  150   23]\n",
      " [   0   64  218   83   52]]\n",
      "====Iteration 9  ====\n",
      "accuracy 0.570068584297\n",
      "confusion matrix\n",
      " [[   0  117    1    0    1]\n",
      " [   0 2656 1405   14    8]\n",
      " [   0  652 2721   49   10]\n",
      " [   0  166 1370  134   48]\n",
      " [   0   70  219   70   58]]\n"
     ]
    }
   ],
   "source": [
    "iter_num=0\n",
    "\n",
    "# the indices are the rows used for training and testing in each iteration\n",
    "for train_indices, test_indices in sss.split(X,y.tolist()): \n",
    "    X_train = X[train_indices]  # train indices for X\n",
    "    y_train = y[train_indices]  # train indices for y\n",
    "    \n",
    "    X_test = X[test_indices]    # test indices for X\n",
    "    y_test = y[test_indices]    # test indices for y\n",
    "    \n",
    "    # train the reusable logisitc regression model on the training data\n",
    "    rfe.fit(X_train,y_train)  # train object\n",
    "    y_hat_rfe = rfe.predict(X_test) # get test set precitions\n",
    "\n",
    "    # accuracy and confusion matrix for this iterations of training/testing\n",
    "    acc_rfe1 = mt.accuracy_score(y_test,y_hat_rfe)\n",
    "    conf_rfe1 = mt.confusion_matrix(y_test,y_hat_rfe)\n",
    "    print(\"====Iteration\",iter_num,\" ====\")\n",
    "    print(\"accuracy\", acc_rfe1 )\n",
    "    print(\"confusion matrix\\n\",conf_rfe1)\n",
    "    iter_num+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean accuracy for this model is  0.566751970519\n"
     ]
    }
   ],
   "source": [
    "# Get the mean accuracy\n",
    "\n",
    "# Load the accuracies\n",
    "accuracies_rfe = cross_val_score(rfe, X, y=y, cv=sss) # this also can help with parallelism\n",
    "\n",
    "# Print out the mean \n",
    "mean_rfe = np.mean(accuracies_rfe)\n",
    "print(\"The mean accuracy for this model is \", mean_rfe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model2 = LogisticRegression(penalty='l2', C=0.5)\n",
    "rfe2 = RFE(model2, 10)\n",
    "fit2 = rfe.fit(X, y)\n",
    "# print(\"Num Features:\", fit2.n_features_)\n",
    "# features2 = pd.Series(fit2.support_, index = X.columns)\n",
    "# print(\"Selected Features: \\n\", features2[features2==True])\n",
    "# print(\"Selected Features:\", fit2.support_)\n",
    "# print(\"Feature Ranking:\", fit2.ranking_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====Iteration 0  ====\n",
      "accuracy 0.570682772034\n",
      "confusion matrix\n",
      " [[   0  117    1    0    1]\n",
      " [   0 2651 1420   10    2]\n",
      " [   0  612 2753   57   10]\n",
      " [   0  181 1381  129   27]\n",
      " [   0   67  237   71   42]]\n",
      "====Iteration 1  ====\n",
      "accuracy 0.57088750128\n",
      "confusion matrix\n",
      " [[   0  119    0    0    0]\n",
      " [   0 2641 1432    9    1]\n",
      " [   0  608 2764   53    7]\n",
      " [   0  189 1377  132   20]\n",
      " [   0   64  232   81   40]]\n",
      "====Iteration 2  ====\n",
      "accuracy 0.57017094892\n",
      "confusion matrix\n",
      " [[   0  118    1    0    0]\n",
      " [   0 2626 1423   32    2]\n",
      " [   0  628 2737   60    7]\n",
      " [   0  152 1385  160   21]\n",
      " [   0   33  202  135   47]]\n",
      "====Iteration 3  ====\n",
      "accuracy 0.563619613062\n",
      "confusion matrix\n",
      " [[   0  119    0    0    0]\n",
      " [   0 2622 1445   14    2]\n",
      " [   0  661 2715   51    5]\n",
      " [   0  184 1382  129   23]\n",
      " [   0   72  207   98   40]]\n",
      "====Iteration 4  ====\n",
      "accuracy 0.571808782885\n",
      "confusion matrix\n",
      " [[   0  119    0    0    0]\n",
      " [   0 2676 1391   11    5]\n",
      " [   0  646 2720   56   10]\n",
      " [   0  193 1361  139   25]\n",
      " [   0   75  213   78   51]]\n",
      "====Iteration 5  ====\n",
      "accuracy 0.558194288054\n",
      "confusion matrix\n",
      " [[   0  116    2    0    1]\n",
      " [   0 2555 1506   19    3]\n",
      " [   0  637 2723   60   12]\n",
      " [   0  186 1375  128   29]\n",
      " [   0   83  218   69   47]]\n",
      "====Iteration 6  ====\n",
      "accuracy 0.56392670693\n",
      "confusion matrix\n",
      " [[   0  117    2    0    0]\n",
      " [   0 2589 1468   25    1]\n",
      " [   0  662 2686   78    6]\n",
      " [   0  139 1367  187   25]\n",
      " [   0   40  205  125   47]]\n",
      "====Iteration 7  ====\n",
      "accuracy 0.562595966834\n",
      "confusion matrix\n",
      " [[   0  119    0    0    0]\n",
      " [   0 2562 1491   28    2]\n",
      " [   0  661 2693   72    6]\n",
      " [   0  159 1349  187   23]\n",
      " [   0   34  203  126   54]]\n",
      "====Iteration 8  ====\n",
      "accuracy 0.565871634763\n",
      "confusion matrix\n",
      " [[   0  118    1    0    0]\n",
      " [   0 2640 1427   13    3]\n",
      " [   0  661 2712   48   11]\n",
      " [   0  186 1382  122   28]\n",
      " [   0   76  218   69   54]]\n",
      "====Iteration 9  ====\n",
      "accuracy 0.568533114955\n",
      "confusion matrix\n",
      " [[   0  117    1    0    1]\n",
      " [   0 2642 1420   19    2]\n",
      " [   0  643 2736   48    5]\n",
      " [   0  182 1372  132   32]\n",
      " [   0   81  218   74   44]]\n"
     ]
    }
   ],
   "source": [
    "iter_num=0\n",
    "# the indices are the rows used for training and testing in each iteration\n",
    "for train_indices, test_indices in sss.split(X,y): \n",
    "    X_train = X[train_indices]  # train indices for X\n",
    "    y_train = y[train_indices]  # train indices for y\n",
    "    \n",
    "    X_test = X[test_indices]    # test indices for X\n",
    "    y_test = y[test_indices]    # test indices for y\n",
    "    \n",
    "    # train the reusable logisitc regression model on the training data\n",
    "    rfe2.fit(X_train,y_train)  # train object\n",
    "    y_hat_rfe2 = rfe2.predict(X_test) # get test set precitions\n",
    "\n",
    "    # accuracy and confusion matrix for this iterations of training/testing\n",
    "    acc_rfe2 = mt.accuracy_score(y_test,y_hat_rfe2)\n",
    "    conf_rfe2 = mt.confusion_matrix(y_test,y_hat_rfe2)\n",
    "    print(\"====Iteration\",iter_num,\" ====\")\n",
    "    print(\"accuracy\", acc_rfe2 )\n",
    "    print(\"confusion matrix\\n\",conf_rfe2)\n",
    "    iter_num+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean accuracy for this model is  0.566629132972\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load the accuracies\n",
    "accuracies_rfe2 = cross_val_score(rfe2, X, y=y, cv=sss) # this also can help with parallelism\n",
    "\n",
    "# Print out the mean \n",
    "mean_rfe2 = np.mean(accuracies_rfe2)\n",
    "print(\"The mean accuracy for this model is \", mean_rfe2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model3 = LogisticRegression(penalty='l2', C=0.5)\n",
    "rfe3 = RFE(model3, 20)\n",
    "fit3 = rfe.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====Iteration 0  ====\n",
      "accuracy 0.575391544682\n",
      "confusion matrix\n",
      " [[   0  117    0    1    1]\n",
      " [   0 2850 1137   91    5]\n",
      " [   0  784 2451  182   15]\n",
      " [   0  218 1194  249   57]\n",
      " [   0   59  177  110   71]]\n",
      "====Iteration 1  ====\n",
      "accuracy 0.573344252226\n",
      "confusion matrix\n",
      " [[   0  119    0    0    0]\n",
      " [   0 2736 1242  104    1]\n",
      " [   0  677 2544  205    6]\n",
      " [   0  220 1200  276   22]\n",
      " [   0   52  185  135   45]]\n",
      "====Iteration 2  ====\n",
      "accuracy 0.57385607534\n",
      "confusion matrix\n",
      " [[   0  119    0    0    0]\n",
      " [   0 2729 1243  108    3]\n",
      " [   0  702 2568  155    7]\n",
      " [   0  218 1220  255   25]\n",
      " [   0   70  165  128   54]]\n",
      "====Iteration 3  ====\n",
      "accuracy 0.566690551745\n",
      "confusion matrix\n",
      " [[   0  119    0    0    0]\n",
      " [   0 2726 1256   99    2]\n",
      " [   0  733 2496  195    8]\n",
      " [   0  218 1196  270   34]\n",
      " [   0   64  166  143   44]]\n",
      "====Iteration 4  ====\n",
      "accuracy 0.574879721568\n",
      "confusion matrix\n",
      " [[   0  119    0    0    0]\n",
      " [   0 2854 1194   30    5]\n",
      " [   0  802 2518  100   12]\n",
      " [   0  240 1258  187   33]\n",
      " [   0   73  180  107   57]]\n",
      "====Iteration 5  ====\n",
      "accuracy 0.56761183335\n",
      "confusion matrix\n",
      " [[   0  117    1    0    1]\n",
      " [   0 2775 1269   36    3]\n",
      " [   0  807 2526   87   12]\n",
      " [   0  231 1261  193   33]\n",
      " [   0   77  198   91   51]]\n",
      "====Iteration 6  ====\n",
      "accuracy 0.566792916368\n",
      "confusion matrix\n",
      " [[   0  118    1    0    0]\n",
      " [   0 2677 1378   27    1]\n",
      " [   0  721 2610   94    7]\n",
      " [   0  196 1297  194   31]\n",
      " [   0   72  180  109   56]]\n",
      "====Iteration 7  ====\n",
      "accuracy 0.56832838571\n",
      "confusion matrix\n",
      " [[   0  119    0    0    0]\n",
      " [   0 2761 1279   41    2]\n",
      " [   0  796 2521  108    7]\n",
      " [   0  249 1240  204   25]\n",
      " [   0   62  176  113   66]]\n",
      "====Iteration 8  ====\n",
      "accuracy 0.573139522981\n",
      "confusion matrix\n",
      " [[   0  119    0    0    0]\n",
      " [   0 2849 1202   29    3]\n",
      " [   0  823 2510   89   10]\n",
      " [   0  238 1270  179   31]\n",
      " [   0   71  185  100   61]]\n",
      "====Iteration 9  ====\n",
      "accuracy 0.572320605999\n",
      "confusion matrix\n",
      " [[   0  117    1    0    1]\n",
      " [   0 2853 1194   34    2]\n",
      " [   0  822 2507   98    5]\n",
      " [   0  227 1274  183   34]\n",
      " [   0   86  189   94   48]]\n"
     ]
    }
   ],
   "source": [
    "iter_num=0\n",
    "# the indices are the rows used for training and testing in each iteration\n",
    "for train_indices, test_indices in sss.split(X,y): \n",
    "    X_train = X[train_indices]  # train indices for X\n",
    "    y_train = y[train_indices]  # train indices for y\n",
    "    \n",
    "    X_test = X[test_indices]    # test indices for X\n",
    "    y_test = y[test_indices]    # test indices for y\n",
    "    \n",
    "    # train the reusable logisitc regression model on the training data\n",
    "    rfe3.fit(X_train,y_train)  # train object\n",
    "    y_hat_rfe3 = rfe3.predict(X_test) # get test set precitions\n",
    "\n",
    "    # accuracy and confusion matrix for this iterations of training/testing\n",
    "    acc_rfe3 = mt.accuracy_score(y_test,y_hat_rfe3)\n",
    "    conf_rfe3 = mt.confusion_matrix(y_test,y_hat_rfe3)\n",
    "    print(\"====Iteration\",iter_num,\" ====\")\n",
    "    print(\"accuracy\", acc_rfe3 )\n",
    "    print(\"confusion matrix\\n\",conf_rfe3)\n",
    "    iter_num+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean accuracy for this model is  0.571235540997\n"
     ]
    }
   ],
   "source": [
    "# Load the accuracies\n",
    "accuracies_rfe3 = cross_val_score(rfe3, X, y=y, cv=sss) # this also can help with parallelism\n",
    "\n",
    "# Print out the mean \n",
    "mean_rfe3 = np.mean(accuracies_rfe3)\n",
    "print(\"The mean accuracy for this model is \", mean_rfe3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model4 = LogisticRegression(penalty='l2', C=1.0)\n",
    "rfe4 = RFE(model4, 30)\n",
    "fit4 = rfe.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====Iteration 0  ====\n",
      "accuracy 0.574777356945\n",
      "confusion matrix\n",
      " [[   0  117    1    0    1]\n",
      " [   0 2847 1199   34    3]\n",
      " [   0  781 2534  106   11]\n",
      " [   0  238 1258  186   36]\n",
      " [   0   78  195   96   48]]\n",
      "====Iteration 1  ====\n",
      "accuracy 0.579281400348\n",
      "confusion matrix\n",
      " [[   0  119    0    0    0]\n",
      " [   0 2855 1192   34    2]\n",
      " [   0  755 2565  104    8]\n",
      " [   0  245 1258  189   26]\n",
      " [   0   56  202  109   50]]\n",
      "====Iteration 2  ====\n",
      "accuracy 0.574163169209\n",
      "confusion matrix\n",
      " [[   0  119    0    0    0]\n",
      " [   0 2828 1216   35    4]\n",
      " [   0  803 2554   68    7]\n",
      " [   0  264 1253  170   31]\n",
      " [   0   73  181  106   57]]\n",
      "====Iteration 3  ====\n",
      "accuracy 0.571501689016\n",
      "confusion matrix\n",
      " [[   0  119    0    0    0]\n",
      " [   0 2824 1158   99    2]\n",
      " [   0  785 2454  184    9]\n",
      " [   0  241 1188  253   36]\n",
      " [   0   62  167  136   52]]\n",
      "====Iteration 4  ====\n",
      "accuracy 0.576005732419\n",
      "confusion matrix\n",
      " [[   0  119    0    0    0]\n",
      " [   0 2865 1177   36    5]\n",
      " [   0  808 2504  105   15]\n",
      " [   0  237 1243  196   42]\n",
      " [   0   69  178  108   62]]\n",
      "====Iteration 5  ====\n",
      "accuracy 0.568430750333\n",
      "confusion matrix\n",
      " [[   0  117    1    0    1]\n",
      " [   0 2752 1291   38    2]\n",
      " [   0  781 2556   83   12]\n",
      " [   0  227 1267  192   32]\n",
      " [   0   74  204   86   53]]\n",
      "====Iteration 6  ====\n",
      "accuracy 0.566281093254\n",
      "confusion matrix\n",
      " [[   0  118    1    0    0]\n",
      " [   0 2786 1268   27    2]\n",
      " [   0  827 2508   90    7]\n",
      " [   0  241 1261  180   36]\n",
      " [   0   81  169  109   58]]\n",
      "====Iteration 7  ====\n",
      "accuracy 0.567918927219\n",
      "confusion matrix\n",
      " [[   0  119    0    0    0]\n",
      " [   0 2773 1270   38    2]\n",
      " [   0  799 2515  107   11]\n",
      " [   0  255 1234  194   35]\n",
      " [   0   63  174  114   66]]\n",
      "====Iteration 8  ====\n",
      "accuracy 0.57385607534\n",
      "confusion matrix\n",
      " [[   0  119    0    0    0]\n",
      " [   0 2869 1178   33    3]\n",
      " [   0  828 2495   98   11]\n",
      " [   0  240 1260  177   41]\n",
      " [   0   71  187   94   65]]\n",
      "====Iteration 9  ====\n",
      "accuracy 0.573446616849\n",
      "confusion matrix\n",
      " [[   0  117    1    0    1]\n",
      " [   0 2860 1176   44    3]\n",
      " [   0  818 2494  112    8]\n",
      " [   0  234 1250  194   40]\n",
      " [   0   80  188   95   54]]\n"
     ]
    }
   ],
   "source": [
    "iter_num=0\n",
    "# the indices are the rows used for training and testing in each iteration\n",
    "for train_indices, test_indices in sss.split(X,y): \n",
    "    X_train = X[train_indices]  # train indices for X\n",
    "    y_train = y[train_indices]  # train indices for y\n",
    "    \n",
    "    X_test = X[test_indices]    # test indices for X\n",
    "    y_test = y[test_indices]    # test indices for y\n",
    "    \n",
    "    # train the reusable logisitc regression model on the training data\n",
    "    rfe4.fit(X_train,y_train)  # train object\n",
    "    y_hat_rfe4 = rfe4.predict(X_test) # get test set precitions\n",
    "\n",
    "    # accuracy and confusion matrix for this iterations of training/testing\n",
    "    acc_rfe4 = mt.accuracy_score(y_test,y_hat_rfe4)\n",
    "    conf_rfe4 = mt.confusion_matrix(y_test,y_hat_rfe4)\n",
    "    print(\"====Iteration\",iter_num,\" ====\")\n",
    "    print(\"accuracy\", acc_rfe4 )\n",
    "    print(\"confusion matrix\\n\",conf_rfe4)\n",
    "    iter_num+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean accuracy for this model is  0.572566281093\n"
     ]
    }
   ],
   "source": [
    "# Load the accuracies\n",
    "accuracies_rfe4 = cross_val_score(rfe4, X, y=y, cv=sss) # this also can help with parallelism\n",
    "\n",
    "# Print out the mean \n",
    "mean_rfe4 = np.mean(accuracies_rfe4)\n",
    "print(\"The mean accuracy for this model is \", mean_rfe4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====Iteration 0  ====\n",
      "accuracy 0.568942573447\n",
      "confusion matrix\n",
      " [[   0  118    1    0    0]\n",
      " [   0 2735 1320   18   10]\n",
      " [   0  702 2664   50   16]\n",
      " [   0  272 1322   79   45]\n",
      " [   0  117  164   56   80]]\n",
      "====Iteration 1  ====\n",
      "accuracy 0.572115876753\n",
      "confusion matrix\n",
      " [[   2  117    0    0    0]\n",
      " [   1 2779 1272   20   11]\n",
      " [   0  757 2602   43   30]\n",
      " [   0  290 1291   84   53]\n",
      " [   0   87  163   45  122]]\n",
      "====Iteration 2  ====\n",
      "accuracy 0.570989865902\n",
      "confusion matrix\n",
      " [[   7  112    0    0    0]\n",
      " [   7 2802 1248   13   13]\n",
      " [   0  788 2618   15   11]\n",
      " [   0  271 1359   26   62]\n",
      " [   0   77  180   35  125]]\n",
      "====Iteration 3  ====\n",
      "accuracy 0.570068584297\n",
      "confusion matrix\n",
      " [[   0  119    0    0    0]\n",
      " [   1 2969 1080   25    8]\n",
      " [   0  950 2405   60   17]\n",
      " [   0  316 1261   87   54]\n",
      " [   0   65  160   84  108]]\n",
      "====Iteration 4  ====\n",
      "accuracy 0.575801003173\n",
      "confusion matrix\n",
      " [[   5  114    0    0    0]\n",
      " [   3 2872 1175   24    9]\n",
      " [   0  827 2508   71   26]\n",
      " [   0  247 1298  101   72]\n",
      " [   0   62  150   66  139]]\n",
      "====Iteration 5  ====\n",
      "accuracy 0.566281093254\n",
      "confusion matrix\n",
      " [[   0  119    0    0    0]\n",
      " [   0 2648 1386   39   10]\n",
      " [   0  709 2649   52   22]\n",
      " [   0  265 1279  124   50]\n",
      " [   0   93  155   58  111]]\n",
      "====Iteration 6  ====\n",
      "accuracy 0.560855768246\n",
      "confusion matrix\n",
      " [[   2  117    0    0    0]\n",
      " [   2 2690 1353   30    8]\n",
      " [   0  775 2583   61   13]\n",
      " [   0  317 1259   93   49]\n",
      " [   0  107  129   70  111]]\n",
      "====Iteration 7  ====\n",
      "accuracy 0.570989865902\n",
      "confusion matrix\n",
      " [[   6  113    0    0    0]\n",
      " [   3 2780 1223   62   15]\n",
      " [   0  822 2472  110   28]\n",
      " [   0  275 1188  196   59]\n",
      " [   0   59  130  104  124]]\n",
      "====Iteration 8  ====\n",
      "accuracy 0.573548981472\n",
      "confusion matrix\n",
      " [[   5  114    0    0    0]\n",
      " [   5 2800 1240   30    8]\n",
      " [   1  775 2568   63   25]\n",
      " [   0  229 1323  124   42]\n",
      " [   0   59  164   88  106]]\n",
      "====Iteration 9  ====\n",
      "accuracy 0.570580407411\n",
      "confusion matrix\n",
      " [[   1  116    1    0    1]\n",
      " [   1 3001 1051   22    8]\n",
      " [   0  986 2382   49   15]\n",
      " [   0  302 1278   66   72]\n",
      " [   0   80  173   40  124]]\n"
     ]
    }
   ],
   "source": [
    "# LR model #1\n",
    "lr_clf = LogisticRegression(penalty='l2', C=1.0) # get object\n",
    "\n",
    "iter_num=0\n",
    "# the indices are the rows used for training and testing in each iteration\n",
    "for train_indices, test_indices in sss.split(X,y): \n",
    "    X_train = X[train_indices]  # train indices for X\n",
    "    y_train = y[train_indices]  # train indices for y\n",
    "    \n",
    "    X_test = X[test_indices]    # test indices for X\n",
    "    y_test = y[test_indices]    # test indices for y\n",
    "    \n",
    "    # train the reusable logisitc regression model on the training data\n",
    "    lr_clf.fit(X_train,y_train)  # train object\n",
    "    y_hat = lr_clf.predict(X_test) # get test set precitions\n",
    "\n",
    "    # accuracy and confusion matrix for this iterations of training/testing\n",
    "    acc = mt.accuracy_score(y_test,y_hat)\n",
    "    conf = mt.confusion_matrix(y_test,y_hat)\n",
    "    print(\"====Iteration\",iter_num,\" ====\")\n",
    "    print(\"accuracy\", acc )\n",
    "    print(\"confusion matrix\\n\",conf)\n",
    "    iter_num+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean accuracy for this model is  0.570017401986\n"
     ]
    }
   ],
   "source": [
    "# Load the accuracies\n",
    "accuracies_lr_clf = cross_val_score(lr_clf, X, y=y, cv=sss) # this also can help with parallelism\n",
    "\n",
    "# Print out the mean \n",
    "mean_lr_clf = np.mean(accuracies_lr_clf)\n",
    "print(\"The mean accuracy for this model is \", mean_lr_clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
